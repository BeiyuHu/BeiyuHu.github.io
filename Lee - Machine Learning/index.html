<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="icon" href="/favicon/favicon.ico">
    <!--Description-->
    
        <meta name="description" content="BEIYUHU&#39;S STUDY ROOM">
    

    <!--Author-->
    
        <meta name="author" content="BEIYU HU">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="Lee - Machine Learning"/>
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content=""/>

    <!--Page Cover-->
    
        <meta property="og:image" content=""/>
    

    <!-- Title -->
    
    <title>Lee - Machine Learning - </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/sass/main.css">


    <!--[if lt IE 8]>
        
<script src="/js/ie/html5shiv.js"></script>

    <![endif]-->

    <!--[if lt IE 8]>
        
<link rel="stylesheet" href="/sass/ie8.css">

    <![endif]-->

    <!--[if lt IE 9]>
        
<link rel="stylesheet" href="/sass/ie9.css">

    <![endif]-->

    <!-- Gallery -->
    <link href="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Google Analytics -->
    


<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head>

<body>

    <div id="wrapper">

        <!-- Menu -->
        <!-- Header -->
<header id="header">
    <div class="inner">

        <!-- Logo -->
        <a href="/" class="logo">
            <span class="symbol"><img src="/images/BEYUHU.png" alt="" /></span><span class="title"></span>
        </a>

        <!-- Nav -->
        <nav>
            <ul>
                <li><a href="#menu">M E N U</a></li>
            </ul>
        </nav>

    </div>
</header>

<!-- Menu -->
<nav id="menu">
    <h2>M E N U</h2>
    <ul>
        
            <li>
                <a href="/">H O M E</a>
            </li>
        
            <li>
                <a href="/archives">C O L L E C T I O N</a>
            </li>
        
            <li>
                <a href="/CV.pdf">C V</a>
            </li>
        
            <li>
                <a target="_blank" rel="noopener" href="https://linkedin.com/in/beiyuhu">L i n k e d I n</a>
            </li>
        
    </ul>
</nav>


        <div id="main">
            <div class="inner">

                <!-- Main Content -->
                

    <h1>Lee - Machine Learning</h1>



<!-- Gallery -->


<!-- Content -->
<p><em>The notes are taken following <a target="_blank" rel="noopener" href="https://speech.ee.ntu.edu.tw/~tlkagk/">Hung-yi Lee</a>â€˜s machine learning theoretical course with the main contents in Chinese. The lectures are underlined as â€œThe Best Machine Learning Material In Chinese Languageâ€. The table below shows the contents I followed and the tasks could be directly jumped into by clicking the hyperlink.</em></p>
<p id="index"></p>

<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:right">INDEX</th>
<th>CONTENT</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"></td>
<td><em>Hung-yi Leeâ€™s 2017 Lecture</em></td>
</tr>
<tr>
<td style="text-align:right"><a href="#task01">TASK01</a></td>
<td>P1 Intro to Machine Learning<br>P2 Why should we learn ML?</td>
</tr>
<tr>
<td style="text-align:right"><a href="#task02">TASK02</a></td>
<td>P3 Regression<br>P4 Regression (demo)</td>
</tr>
<tr>
<td style="text-align:right"><a href="#task03">TASK03</a></td>
<td>P5 Where are the errors from?<br>P6 Gradient Descent<br>P7 Gradient Descent - AOE<br>P8 Gradient Descent - Minecraft</td>
</tr>
<tr>
<td style="text-align:right"><a href="#task04">TASK04</a></td>
<td>P13 Deep Learning<br>P14 Backpropagation</td>
</tr>
<tr>
<td style="text-align:right"></td>
<td><em>Hung-yi Leeâ€™s 2021 Lecture</em></td>
</tr>
<tr>
<td style="text-align:right"><a href="#task05">TASK05</a></td>
<td>P5 Local minima vs Saddle point<br>P6 Batch vs Momentum<br>P7 Learning Rate<br>P8 Optimization by loss function<br>P9 Batch Normalization</td>
</tr>
<tr>
<td style="text-align:right"><a href="#task06">TASK06</a></td>
<td>P10 Convolutional Neural Network (CNN)</td>
</tr>
</tbody>
</table>
</div>
<p id="task01"></p>
<p align="center"> - - - - - - - - - - - - - - - T A S K 0 1 - - - - - - - - - - - - - - -
<br><a href="#index">[ B A C K ]</a></p>

<p><img src="HUNGYILEE_01.png" width="100%"></p>
<p align="center"> </p>

<h1 id="P1-æœºå™¨å­¦ä¹ ä»‹ç»"><a href="#P1-æœºå™¨å­¦ä¹ ä»‹ç»" class="headerlink" title="P1 æœºå™¨å­¦ä¹ ä»‹ç»"></a>P1 æœºå™¨å­¦ä¹ ä»‹ç»</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ht411g7Ef?p=1">Hung-yi Lee - Machine Learning 2017 - P1 æœºå™¨å­¦ä¹ ä»‹ç»</a></p>
<p align="center"><img src="learningMap.png" width="80%"></p>

<h2 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h2><h4 id="1-Regression-ï¼ˆå›å½’ï¼‰"><a href="#1-Regression-ï¼ˆå›å½’ï¼‰" class="headerlink" title="1. Regression ï¼ˆå›å½’ï¼‰"></a>1. Regression ï¼ˆå›å½’ï¼‰</h4><ul>
<li>The output of the target function f is â€˜scalarâ€™.</li>
<li>è®¨è®ºè‡ªå˜é‡xå’Œå› å˜é‡yçš„çº¿æ€§å…³ç³»ï¼Œæ„å»ºæ–¹ç¨‹ï¼Œæ¨è®ºå’Œé¢„æµ‹y</li>
<li><em>example:</em></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Input</th>
<th style="text-align:center">Output</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Historical PM2.5 â†’</td>
<td style="text-align:center">Predicted PM2.5</td>
</tr>
</tbody>
</table>
</div>
<h4 id="2-Classification"><a href="#2-Classification" class="headerlink" title="2. Classification"></a>2. Classification</h4><ul>
<li>Binary Classification äºŒå…ƒåˆ†æ³•: YES/NO</li>
<li><p>Multi-class Classification å¤šå…ƒåˆ†æ³•: ex: æ–°é—»åˆ†ç±»</p>
<ol>
<li><p>Model (Function)</p>
<ul>
<li>Linear model</li>
<li>Non-linear model<ul>
<li>Deep learning<br><em>example:</em></li>
</ul>
<ol>
<li>IMAGE RECOGNITION (Hierarchy structure)    </li>
<li>Playing GO: n*n çš„é€‰æ‹©é¢˜</li>
</ol>
<ul>
<li>SVM, decision tree, KNN</li>
</ul>
</li>
</ul>
</li>
<li><p>Training data:</p>
<ul>
<li>Input/output: Pair of target function</li>
<li>Function: Output = <strong>label</strong> (å¾€å¾€éœ€è¦å¤§é‡labeled data) </li>
</ul>
</li>
</ol>
</li>
</ul>
<h4 id="3-Structured-Learning"><a href="#3-Structured-Learning" class="headerlink" title="3. Structured Learning"></a>3. Structured Learning</h4><ul>
<li>Beyond Classification<blockquote>
<p>æœºå™¨è¦è¾“å‡ºçš„æ˜¯å¤æ‚çš„ç‰©ä»¶</p>
</blockquote>
</li>
<li>Ex:<blockquote>
<p>Speech Recognition<br>Machine Translation<br>äººè„¸è¯†åˆ«</p>
</blockquote>
</li>
</ul>
<h2 id="Additional-scenario"><a href="#Additional-scenario" class="headerlink" title="Additional scenario"></a>Additional scenario</h2><p><strong>æ˜¯å¦æœ‰å…¶ä»–æ— éœ€å¤§é‡labeled dataçš„å­¦ä¹ ï¼ŸYESï¼šâ†“</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>n.</th>
<th>scenario</th>
<th>ç‰¹ç‚¹</th>
</tr>
</thead>
<tbody>
<tr>
<td>a.</td>
<td>Semi-supervised Learningï¼š</td>
<td>å¯ä»¥åˆ©ç”¨å­¦ä¹ ä¸­æœ‰äº›æœªè¢«labelçš„dataset</td>
</tr>
<tr>
<td>b.</td>
<td>Transfer Learningï¼š</td>
<td>æ— ç›¸å¹²çš„datasetï¼Œå¦‚ï¼šè®­ç»ƒçŒ«ç‹—è¯†åˆ«çš„ç…§ç‰‡ï¼Œç»™äº†å…¶ä»–å¦‚å¤§è±¡ã€åŠ¨æ¼«ç­‰å›¾ç‰‡</td>
</tr>
<tr>
<td>c.</td>
<td>Unsupervised Learning</td>
<td></td>
</tr>
<tr>
<td>d.</td>
<td>Reinforcement Learningï¼š</td>
<td>å› ä¸ºæ²¡æœ‰åŠæ³•dataåšsupervised learningï¼Œå¦‚æœèƒ½åšsupervised learningå°±ä¸ä¼šåšreinforcement learning</td>
</tr>
</tbody>
</table>
</div>
<p>åŒºåˆ«ï¼š</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Supervised</th>
<th>vs</th>
<th>Reinforcement</th>
</tr>
</thead>
<tbody>
<tr>
<td>Learn from <strong>teacher</strong></td>
<td>â†â†’</td>
<td>Learn from <strong>critics</strong></td>
</tr>
</tbody>
</table>
</div>
<p>Alpha GO is supervised + reinforcement learning (æœºå™¨è·Ÿæœºå™¨ä¸‹æ£‹ï¼Œè‡ªå·±è·Ÿè‡ªå·±ä¸‹æ£‹)</p>
<hr>
<h1 id="P2-ä¸ºä»€ä¹ˆè¦å­¦ä¹ æœºå™¨å­¦ä¹ "><a href="#P2-ä¸ºä»€ä¹ˆè¦å­¦ä¹ æœºå™¨å­¦ä¹ " class="headerlink" title="P2 ä¸ºä»€ä¹ˆè¦å­¦ä¹ æœºå™¨å­¦ä¹ "></a>P2 ä¸ºä»€ä¹ˆè¦å­¦ä¹ æœºå™¨å­¦ä¹ </h1><p>by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ht411g7Ef?p=2">Hung-yi Lee - Machine Learning 2017 - P2 ä¸ºä»€ä¹ˆè¦å­¦ä¹ æœºå™¨å­¦ä¹ </a></p>
<p>AIè®­ç»ƒå¸ˆæŒ‡å¯¼AIï¼Œç±»æ¯”Pokemonçš„è®­ç»ƒå¸ˆï¼ˆï¼Ÿï¼Ÿï¼Ÿï¼‰</p>
<p id="task02"></p>
<p align="center">- - - - - - - - - - - - - - - T A S K 0 2 - - - - - - - - - - - - - - -<br><a href="#index">[ B A C K ]</a></p>

<p><img src="HUNGYILEE_02.png" width="100%"></p>
<p align="center"> </p>


<h1 id="P3-Regression-å›å½’"><a href="#P3-Regression-å›å½’" class="headerlink" title="P3 Regression å›å½’"></a>P3 Regression å›å½’</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ht411g7Ef?p=3">Hung-yi Lee - Machine Learning 2017 - P3 Regression</a></p>
<p>Qï¼šRegression å¯ä»¥åšä»€ä¹ˆï¼Ÿ<br>Aï¼šå¯ä»¥æ˜¯ï¼šé¢„æµ‹è‚¡ç¥¨ã€è‡ªåŠ¨é©¾é©¶ã€æ¨èç­‰ â†’ <em>f(x) = y (= PREDICT)</em><br><code>input x: information</code> â†’ <code>output y: scalar</code></p>
<hr>
<h4 id="ç®€å•æ¨¡å‹ï¼ˆæ­¥éª¤è§£æï¼‰ï¼š"><a href="#ç®€å•æ¨¡å‹ï¼ˆæ­¥éª¤è§£æï¼‰ï¼š" class="headerlink" title="ç®€å•æ¨¡å‹ï¼ˆæ­¥éª¤è§£æï¼‰ï¼š"></a>ç®€å•æ¨¡å‹ï¼ˆæ­¥éª¤è§£æï¼‰ï¼š</h4><p> ä»¥ä¸‹å°†ä»¥ <em>exampleï¼šPokemonè¿›åŒ–åçš„Combat Poweré¢„æµ‹</em> å±•å¼€ï¼š</p>
<p align="center"><img src="CP_predict.png" width="60%"></p>


<p>å…¶ä¸­ x = or( x_cp, x_s, x_hp, x_w, x_h ) è€Œé¢„æµ‹ y_cpï¼ˆä¸‹æ–‡ä»…è®¾å‚ x<sub>cp</sub>ï¼‰</p>
<ul>
<li>Recap åšMLçš„ä¸‰ä¸ªæ­¥éª¤ï¼š</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Step 1.</td>
<td>æ‰¾ä¸€ä¸ªmodel</td>
</tr>
<tr>
<td>Step 2.</td>
<td>å®šä¹‰function set é‡Œ evaluateå®ƒçš„å¥½å</td>
</tr>
<tr>
<td>Step 3.</td>
<td>æ‰¾å‡ºæœ€å¥½çš„function</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h5 id="Step-1-Model"><a href="#Step-1-Model" class="headerlink" title="Step 1: Model"></a><strong>Step 1</strong>: Model</h5><p>æ‰¾function set å°±æ˜¯æ‰€è°“çš„model <em>#å­˜ç–‘</em></p>
<p><code>Model</code> â†’ <code>a set of function: f1, f2, ...</code></p>
<ul>
<li>è¿™å…¶ä¸­ï¼š f(x) = y = b + w <em> x<sub>cp</sub> (w å’Œ b å¯ä¸º<em>*ä»»æ„å€¼</em></em>)<br>å°±å¯ä»¥ä»£å…¥ä¸åŒwåŠbï¼Œæœ‰æ— é™ç»„f(x)ã€‚ä½†åŒæ—¶æœ‰äº›æ˜¾ç„¶ä¸åˆç†çš„functionï¼Œå°†ä¼šè¢«ä¹‹åçš„è®­ç»ƒé›†ä¸­ç­›é™¤ã€‚</li>
</ul>
<p>ç”±äºå…¶çº¿æ€§å…³ç³»ï¼Œä¹Ÿç§°ä¸ºï¼š</p>
<p><code>Linear model</code> â†’ <code>y = b + Î£w_i*x_i</code></p>
<ul>
<li><code>b</code>: bias åå·®</li>
<li><code>w_i</code>: weight æƒé‡</li>
<li><code>x_i</code>: input x</li>
</ul>
<h5 id="Step-2-Goodness-of-Function"><a href="#Step-2-Goodness-of-Function" class="headerlink" title="Step 2: Goodness of Function"></a><strong>Step 2</strong>: Goodness of Function</h5><p><code>evaluate functionçš„å¥½å</code> ï¼š <code>1. æ”¶é›†training data</code>â†’<code>2. æ‰¾å‡ºfunction</code></p>
<ol>
<li>Training data: 10 pokemons (<a target="_blank" rel="noopener" href="https://www.openintro.org/stat/data/?data=pokemon">source</a>)<br><img src="trainingData.png" width="80%"></li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">input x<sub>cp</sub></th>
<th style="text-align:center">output y<sub>cp</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">x<sup>1</sup></td>
<td style="text-align:center">y<sup>^1</sup></td>
</tr>
<tr>
<td style="text-align:center">x<sup>2</sup></td>
<td style="text-align:center">y<sup>^2</sup></td>
</tr>
<tr>
<td style="text-align:center">x<sup>3</sup></td>
<td style="text-align:center">y<sup>^3</sup></td>
</tr>
<tr>
<td style="text-align:center">â€¦</td>
<td style="text-align:center">â€¦</td>
</tr>
<tr>
<td style="text-align:center">x<sup>10</sup></td>
<td style="text-align:center">y<sup>^10</sup></td>
</tr>
</tbody>
</table>
</div>
<ol>
<li>Loss function <strong><em>L</em></strong>:</li>
</ol>
<ul>
<li>è¿™é‡Œinputæ˜¯ä¸€ä¸ªfunctionï¼Œoutputæ˜¯å…¶<strong>ä¼°æµ‹è¯¯å·®</strong><br>L(f) <code>inputä¸ºå‡½æ•°</code><br>= L (w, b) <code>å³inputä¸ºwå’Œb</code><br>= Î£<sup>10</sup><sub>n=1</sub> (y<sup>^n</sup> -  f(x<sup>n</sup><sub>cp</sub>) )<sup>2</sup>   <code>è½¬åŒ–ä¸ºy^çœŸå®å€¼ä¸çº¿æ€§å…³ç³»é¢„æµ‹å€¼åå·®çš„å¹³æ–¹ï¼Œå¹³æ–¹ä¸ºæ¶ˆé™¤ç¬¦å·å½±å“</code><br>= Î£<sup>10</sup><sub>n=1</sub> (y<sup>^n</sup> - ( b+w*x<sup>n</sup><sub>cp</sub> ))<sup>2</sup> <code>å±•å¼€</code></li>
</ul>
<p> </p>

<p><img src="lossFunction.png" width="80%"></p>
<ul>
<li>å›¾ä¸­æ¯ä¸ªç‚¹ä»£è¡¨äº†ä¸€ç»„(b,w) å³ä¸ºä¸€ä¸ªfunction</li>
<li>é¢œè‰²è¶Šçº¢ä»£è¡¨Læ•°å€¼è¶Šå¤§ï¼Œå³è¯¯å·®è¶Šå¤§ï¼Œè¡¨ç°è¶Šå·®</li>
</ul>
<h5 id="Step-3-Best-function-â†’-Gradient-Descent"><a href="#Step-3-Best-function-â†’-Gradient-Descent" class="headerlink" title="Step 3: Best function â†’ Gradient Descent"></a><strong>Step 3</strong>: Best function â†’ Gradient Descent</h5><p><code>A set of function</code> â†’<code>Goodness of function f</code>â†<code>GRADIENT DESCENT æ¢¯åº¦é€’å‡</code></p>
<ul>
<li>å¦‚ä½•æ‰¾ä¸€ä¸ªå¥½çš„function f â†’ è¯„ä¼°ä»¥ä¸‹çš„ fï¼Š<br>  <em>f</em>ï¼Š= <em>arg</em> <em>min<sub>f</sub></em> L(f)<br>  <em>w</em>ï¼Š, <em>b</em>ï¼Š= <em>arg</em> <em>min<sub>f</sub></em> L(w, b)<br>  å³ï¼šå– L(f) æœ€å°æ—¶çš„ f å€¼ ï¼ˆ<em> arg: argumentï¼‰
</em>è¿™é‡Œå¯ç”¨çº¿ä»£ç›´æ¥è§£ï¼Œä½†æ˜¯å¤æ‚å‡½æ•°éœ€è¦å¾®åˆ†è§£ï¼Œå¹¶æ±‚å‡ºå¾®åˆ†æœ€å°ï¼ˆå³å¾®åˆ†æ¥è¿‘0ï¼‰*</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Step</th>
<th>Gradient Descent</th>
</tr>
</thead>
<tbody>
<tr>
<td>01</td>
<td>éšæœºé€‰æ‹©åˆå§‹w0, b0</td>
</tr>
<tr>
<td>02</td>
<td>è®¡ç®—wå¯¹Låå¾®åˆ†, bå¯¹Lçš„åå¾®åˆ†</td>
</tr>
<tr>
<td>03</td>
<td>è´Ÿå€¼(æ–œç‡ä¸‹é™) â†’ å¾€å³ / æ­£å€¼(æ–œç‡ä¸Šå‡) â†’ å¾€å·¦</td>
</tr>
<tr>
<td>*</td>
<td>step sizeå–å†³äº a.å¾®åˆ†å¤§å° b. Î· â€œlearning rateâ€ ï¼ˆå¤§æ—¶æ›´æ–°å¹…åº¦å¤§ã€å­¦ä¹ æ•ˆç‡å¿«ï¼‰</td>
</tr>
<tr>
<td>04</td>
<td>å¤šæ¬¡è¿­ä»£åï¼šæ‰¾å‡ºlocal optimal <strong>NOT</strong> global optimal (ä½†åœ¨linear regressionä¸æ˜¯é—®é¢˜ï¼Œä¸‹æ–¹è§£é‡Š)</td>
</tr>
</tbody>
</table>
</div>
<p>prosï¼š<br>æ— éœ€ç©·ä¸¾æ‰€æœ‰wå¯¹Loss function L(w)åšå¾®åˆ†</p>
<hr>
<p><em>æ’æ’­è§£é‡Š local optimal å’Œ global optimalï¼š</em></p>
<p><strong>æ¢¯åº¦ä¸‹é™ï¼ˆgradient descentï¼‰å›¾å½¢ä¸Šçš„è¡¨è¾¾</strong> </p>
<ul>
<li>æŠŠåå¾®åˆ†æ’æˆä¸€ä¸ªå‘é‡ï¼ˆåœ¨æœ¬ä¾‹ä¸­æ˜¯å‘é‡ï¼‰</li>
<li>åå¾®åˆ†çš„æ¢¯åº¦ä¸‹é™ å³ä¸º ç­‰é«˜çº¿çš„æ³•çº¿æ–¹å‘ â†’ æ‰€ä»¥å®ƒä¼šé€æ¸å¾€ç´«è‰²æ–¹å‘èµ°</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Linear</th>
<th style="text-align:center">Non-linear</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="gradientDescent.png" width="80%"></td>
<td style="text-align:center"><img src="gradientDescent3D.png" width="80%"></td>
</tr>
<tr>
<td style="text-align:center">çº¿æ€§å›å½’çš„æŸå¤±å‡½æ•°ä¸ºconvexï¼Œå³ <strong>æ— </strong> local optimal</td>
<td style="text-align:center"><strong>ä½†</strong> è‹¥éçº¿æ€§å›å½’ï¼šå³æœ‰ local optimalï¼Œåˆæœ‰ global optimal çš„ä½ç½®</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p><strong>å›åˆ°Pokemon CPé¢„æµ‹ï¼š</strong></p>
<p>æ­¤æ—¶è¦ç”¨æ–°çš„testing dataæµ‹è¯•å…¶error â†’ æ³›åŒ–ï¼ˆgeneralizationï¼‰</p>
<center>

çº¿æ€§ç»“æœ y = (-188.4) + 2.7 * x<sub>cp</sub>



||Training |Testing |
| ---: | :---: | :---: |
|Error ***L(f)*** |31.9|35     |

</center>


<p>æœ€ç»ˆçš„çº¿æ€§å…³ç³»å¼ä¸º ï¼Œå…¶è¯¯å·®ä¸º31.9ï¼›<strong>ä½†</strong> è¾“å…¥å¦å¤–ä¸€ç»„10ä¸ªPokemonæ•°å€¼ä½œä¸ºtesting dataï¼Œè¯¯å·®ä¸º 35ã€‚å³ é¢„æµ‹ä¸å‡†ç¡®ã€‚</p>
<hr>
<h4 id="å¤æ‚æ¨¡å‹ï¼ˆæå‡å‡†ç¡®æ€§ï¼‰ï¼š"><a href="#å¤æ‚æ¨¡å‹ï¼ˆæå‡å‡†ç¡®æ€§ï¼‰ï¼š" class="headerlink" title="å¤æ‚æ¨¡å‹ï¼ˆæå‡å‡†ç¡®æ€§ï¼‰ï¼š"></a>å¤æ‚æ¨¡å‹ï¼ˆæå‡å‡†ç¡®æ€§ï¼‰ï¼š</h4><p><strong>OPTION 1: é€‰æ‹©å…¶ä»–modelï¼š</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Model</th>
<th style="text-align:center">Training data</th>
<th style="text-align:center">Testing data</th>
</tr>
</thead>
<tbody>
<tr>
<td>y = b + w<sub>1</sub>Â· x<sub>cp</sub>+w<sub>2</sub>Â·(x<sub>cp</sub>)<sup>2</sup></td>
<td style="text-align:center">15.4</td>
<td style="text-align:center">18.4</td>
</tr>
<tr>
<td>y = b + w<sub>1</sub>Â· x<sub>cp</sub>+w<sub>2</sub>Â·(x<sub>cp</sub>)<sup>2</sup>+w<sub>3</sub>Â·(x<sub>cp</sub>)<sup>3</sup></td>
<td style="text-align:center">15.3</td>
<td style="text-align:center">18.1</td>
</tr>
<tr>
<td>y = b + w<sub>1</sub>Â· x<sub>cp</sub>+w<sub>2</sub>Â·(x<sub>cp</sub>)<sup>2</sup>+w<sub>3</sub>Â·(x<sub>cp</sub>)<sup>3</sup>+w<sub>4</sub>Â·(x<sub>cp</sub>)<sup>4</sup></td>
<td style="text-align:center">14.9</td>
<td style="text-align:center">28.8</td>
</tr>
<tr>
<td>y = b + w<sub>1</sub>Â· x<sub>cp</sub>+w<sub>2</sub>Â·(x<sub>cp</sub>)<sup>2</sup>+w<sub>3</sub>Â·(x<sub>cp</sub>)<sup>3</sup>+w<sub>4</sub>Â·(x<sub>cp</sub>)<sup>4</sup>+w<sub>5</sub>Â·(x<sub>cp</sub>)<sup>5</sup></td>
<td style="text-align:center">12.8</td>
<td style="text-align:center">232.1</td>
</tr>
</tbody>
</table>
</div>
<p>Modelç»´åº¦çš„æå‡ä¼šå¢åŠ  training dataçš„å‡†ç¡®åº¦ï¼Œ<strong>ä½†ï¼</strong> å¤æ‚modelå¯¼è‡´äº†testing dataå¾ˆç³Ÿç³•ã€‚<br>å³ï¼š<strong>OVERFITTING è¿‡æ‹Ÿåˆ</strong> â†’ é€‰æ‹©æœ€åˆé€‚çš„modelï¼Œæ­¤ä¾‹ä¸º<strong>ç»´åº¦3</strong>çš„ã€‚</p>
<p><strong>OPTION 2: ç§ç±»åˆ’åˆ†åšä¸åŒçš„regressionæ–¹ç¨‹</strong><br>(å‰ææ•°æ®é›†å¤Ÿå¤š)</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>species 1</th>
<th>species 2</th>
<th>species 3 and more</th>
</tr>
</thead>
<tbody>
<tr>
<td>y =</td>
<td>b<sub>1</sub> + w<sub>1</sub> Â· Î´(x<sub>s</sub> = s<sub>1</sub>) Â· x<sub>cp</sub></td>
<td>+b<sub>2</sub> + w<sub>2</sub> Â· Î´(x<sub>s</sub> = s<sub>2</sub>) Â· x<sub>cp</sub></td>
<td>+b<sub>3</sub> + w<sub>3</sub> Â· Î´(x<sub>s</sub> = s<sub>3</sub>) Â· x<sub>cp</sub>     +â€¦</td>
</tr>
</tbody>
</table>
</div>
<p>å…¶ä¸­çš„ Î´() ä¸ºBoolean(true = 1, false = 0)çš„filterï¼Œæ‰€ä»¥å®é™…ä¸Šæ•´ä¸ªå…¬å¼ä¸ºlinear modelã€‚</p>
<center>
<img src="speciesClassification.png" width="60%">
</center>


<ul>
<li><strong>å°½ç®¡è®­ç»ƒé›†å’Œæµ‹è¯•é›†æœ€åçš„ç»“æœå·®åˆ«æœ‰ç‚¹å¤§ï¼Œä½†ä»æµ‹è¯•é›†çš„errorè€Œè¨€æ¯”ä¹‹å‰çš„ç»“æœéƒ½è¦å¥½ã€‚</strong></li>
</ul>
<p><strong>OPTION 3: å¤šå‚æ•°è€ƒè™‘</strong></p>
<ul>
<li><p>Back to step <strong>1</strong>: é™¤äº†CPï¼Œè¿˜å¯è€ƒè™‘ hpã€weightç­‰å‚æ•°ã€‚<br>ç»“æœæ˜¯è®­ç»ƒè¯¯å·®1.9è€Œæµ‹è¯•è¯¯å·®ä¸º102.3ï¼Œå³overfittingã€‚</p>
</li>
<li><p>Back to step <strong>2</strong>: Regularization æ­£åˆ™åŒ–</p>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>åŸæ–¹ç¨‹</th>
<th>æ–°å¢é¡¹</th>
</tr>
</thead>
<tbody>
<tr>
<td>L= Î£<sub>n</sub> (y<sup>^n</sup> - ( b+Î£w<sub>i</sub>x<sub>i</sub>))<sup>2</sup></td>
<td>+Î»Â·Î£(w<sub>i</sub>)<sup>2</sup></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>å…¶ä¸­<code>Î»</code>æ˜¯å¸¸æ•°ï¼Œéœ€è¦<strong>æ‰‹è°ƒ</strong>ï¼›è€Œ æ–°å¢é¡¹ è¶Šå°è¶Šå¥½ã€‚<br>åªæœ‰ <code>w</code> è€Œæ²¡æœ‰ <code>b</code>ï¼Œå› ä¸º <code>w</code> å½±å“äº†å¹³æ»‘ç¨‹åº¦ï¼Œè€Œ <code>b</code> å’Œå¹³æ»‘ç¨‹åº¦æ— å…³ã€‚</li>
</ul>
<p><strong>ä½†</strong> ä¸ºä»€ä¹ˆæœŸå¾…åŠ ä¸Šè¿™ä¸ªé¡¹è¶Šå°è¶Šå¥½å‘¢ï¼Ÿ</p>
<ul>
<li>æ›´å¹³æ»‘ï¼šä½¿å¾— â†’ inputæœ‰å˜åŒ–æ—¶ï¼Œè€Œoutputä¸æ•æ„Ÿ</li>
<li>æ‚è®¯ noise corrupt inputæ—¶ï¼Œsmooth function has less influence.</li>
</ul>
<p>åŒæ—¶ï¼Œä¸ä¸€å®šæ˜¯ <code>Î»</code> æ›´å¤§æ—¶ä¼šæ›´å¥½ï¼›é‚£åº”è¯¥è€ƒè™‘å¤šå¤§çš„ <code>Î»</code> ï¼Ÿ</p>
<ul>
<li>è½¬æŠ˜ç‚¹ä½¿å¾—testing data erroræœ€å°</li>
<li>P4çš„ç»ƒä¹ ç”¨äº†AdaGrad</li>
</ul>
<p><img src="regularization.png" width="80%"></p>
<hr>
<h1 id="P4-Regression-å›å½’"><a href="#P4-Regression-å›å½’" class="headerlink" title="P4 Regression å›å½’"></a>P4 Regression å›å½’</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ht411g7Ef?p=4">Hung-yi Lee - Machine Learning 2017 - P4 Regression - Jupyter notebook</a></p>
<p> Î· learning rate (lr) çš„ update æ¥è¿‘æœ€ä½³è§£</p>
<ul>
<li>æé«˜10å€ â†’ ç›¸å¯¹æ¥è¿‘ï¼Œä½†æœ‰åå¤</li>
<li>æé«˜100å€ â†’ åå¤æ›´å¤š</li>
<li><p>å®¢åˆ¶åŒ–lr â†’ lr for b, lr  for w</p>
<p>ç”¨çš„AdaGradçš„æ–¹æ³•ï¼š</p>
<p><code>lr_b = lr_b + b_grad**2</code><br><code>lr_w = lr_w + w_grad**2</code><br><code># Update parameters</code><br><code>b = b - lr/np.squrt(lr_b) * b_grad</code><br><code>w = w - lr/np.squrt(lr_w) * w_grad</code></p>
</li>
</ul>
<p> å‚è€ƒï¼š</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://databricks.com/glossary/adagrad#:~:text=Adaptive%20Gradient%20Algorithm%20(Adagrad">databricks _ AdaGrad</a>%20is,incorporating%20knowledge%20of%20past%20observations.)</li>
<li><p><a target="_blank" rel="noopener" href="https://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<p id="task03"></p>
<p align="center">- - - - - - - - - - - - - - - T A S K 0 3 - - - - - - - - - - - - - - -<br><a href="#index">[ B A C K ]</a></p>

</li>
</ol>
<p><img src="HUNGYILEE_03.png" width="100%"></p>
<p align="center"> </p>

<h1 id="P5-è¯¯å·®ä»å“ªé‡Œæ¥"><a href="#P5-è¯¯å·®ä»å“ªé‡Œæ¥" class="headerlink" title="P5 è¯¯å·®ä»å“ªé‡Œæ¥"></a>P5 è¯¯å·®ä»å“ªé‡Œæ¥</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ht411g7Ef?p=5">Hung-yi Lee - Machine Learning 2017 - P5 è¯¯å·®ä»å“ªé‡Œæ¥</a></p>
<p>Qï¼šWhere does the erro come fromï¼Ÿ<br>Aï¼šæ¥è‡ªäº <code>1. bias</code> <code>2. variance</code></p>
<blockquote>
<p><strong>å¦‚æœä½ èƒ½è¯Šæ–­ä½ errorçš„æ¥æºï¼Œé‚£ä½ å°±æœ‰é€‚å½“çš„åŠæ³•improveä½ çš„model</strong></p>
</blockquote>
<hr>
<h2 id="Estimator"><a href="#Estimator" class="headerlink" title="Estimator"></a>Estimator</h2><p>ä¸‹æ–‡å°†ä¼šæåŠï¼š</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">çœŸå®å‡½æ•°</th>
<th style="text-align:center">é¢„ä¼°å‡½æ•°</th>
<th style="text-align:center">å¹³å‡å‡½æ•°</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">f<sup>^</sup> (f head)</td>
<td style="text-align:center">f<em> (f star</em>)</td>
<td style="text-align:center">E[f*] =  f- (f bar)</td>
</tr>
</tbody>
</table>
</div>
<p>å°†ä»¥ <strong>æ‰“é¶</strong> ä¸ºä¾‹å­è¿›è¡Œå±•å¼€ï¼š</p>
<ul>
<li>çœŸå®å‡½æ•° f^ ä¸º <strong>é¶å¿ƒ</strong></li>
<li>ä¼°æµ‹å‡½æ•° f<em> ä¸º <em>*å°è¯•æ‰“é¶å‡»ä¸­çš„ä½ç½®</em></em></li>
<li>å…¶ä¹‹é—´çš„å·®è· = Bias + Variance</li>
</ul>
<hr>
<h2 id="1-ç†è®ºç»Ÿè®¡å­¦ä¾‹å­ï¼š"><a href="#1-ç†è®ºç»Ÿè®¡å­¦ä¾‹å­ï¼š" class="headerlink" title="1. ç†è®ºç»Ÿè®¡å­¦ä¾‹å­ï¼š"></a>1. ç†è®ºç»Ÿè®¡å­¦ä¾‹å­ï¼š</h2><p>é¢„æµ‹<strong>æœªçŸ¥æ•°x</strong>çš„å‡å€¼</p>
<blockquote>
<ul>
<li>å‡è®¾1 å…¶å‡å€¼ä¸º Î¼</li>
<li>å‡è®¾2 å…¶æ–¹å·®ä¸º Ïƒ<sup>2</sup></li>
<li>å‡è®¾3 N ä¸ªsampleç‚¹ { x<sup>1</sup>, x<sup>2</sup>, x<sup>3</sup>,â€¦,x<sup>N</sup> }</li>
</ul>
</blockquote>
<ol>
<li>Estimator of å‡å€¼ Î¼ ï¼š unbiased estimator<br> m = 1/N <em> Î£ x<sup>n</sup> <em>*â‰  Î¼</em></em><br> Var[m] = Ïƒ<sup>2</sup>/Nï¼Œæ–¹å·®å–å†³äºsampleæ•°é‡Nï¼ŒNå¤§æ—¶ mçš„æ–¹å·®å°<br> è™½ç„¶ m â‰  Î¼ï¼Œä½† E[m] ä¼šæ­£å¥½ç­‰äºÎ¼</li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">å‡å€¼ m</th>
<th style="text-align:center">N æ•°å°‘</th>
<th style="text-align:center">N æ•°å¤§</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="bias1.png" width="30%"></td>
<td style="text-align:center"><img src="SmallerN.png" width="30%"></td>
<td style="text-align:center"><img src="LargerN.png" width="30%"></td>
</tr>
</tbody>
</table>
</div>
<ol>
<li><p>Estimator of æ–¹å·®  Ïƒ<sup>2</sup><br> m = 1/N <em> Î£ x<sup>n</sup>ï¼Œå†è®¡ç®— s<sup>2</sup>=1/N</em>Î£(x<sup>n</sup>-m)<sup>2</sup> <strong>â‰  Ïƒ<sup>2</sup></strong></p>
<p> <strong>Biased estimator:</strong><br> E[s<sup>2</sup>] = (N-1) / N * Ïƒ<sup>2</sup>ï¼Œæ—¢è€ƒè™‘äº†måˆè€ƒè™‘äº†Ïƒ</p>
</li>
</ol>
<hr>
<h2 id="2-åˆ°åº•-bias-å’Œ-variance-æ˜¯ä»€ä¹ˆï¼Ÿ"><a href="#2-åˆ°åº•-bias-å’Œ-variance-æ˜¯ä»€ä¹ˆï¼Ÿ" class="headerlink" title="2. åˆ°åº• bias å’Œ variance æ˜¯ä»€ä¹ˆï¼Ÿ"></a>2. åˆ°åº• bias å’Œ variance æ˜¯ä»€ä¹ˆï¼Ÿ</h2><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">ä»¥ä¸‹è¡¨é¶å›¾é€»è¾‘</th>
</tr>
</thead>
<tbody>
<tr>
<td>Bias</td>
<td style="text-align:center"><strong>é¶å¿ƒ(f^)</strong> å’Œ <strong>é¢„ä¼°é¢„æµ‹å‡½æ•°çš„å¹³å‡å‡½æ•°(f_)</strong> çš„è·ç¦»</td>
</tr>
<tr>
<td>Variance</td>
<td style="text-align:center"><strong>é¢„ä¼°é¢„æµ‹å‡½æ•°(fï¼Š)</strong> å’Œ <strong>å¹³å‡å‡½æ•°(f_)</strong> çš„ç¦»æ•£ç¨‹åº¦</td>
</tr>
<tr>
<td>Diagram</td>
<td style="text-align:center"><img src="bias+variance.png" width="50%"></td>
</tr>
</tbody>
</table>
</div>
<p><code>example 1</code> <em>prerequisite</em> </p>
<ul>
<li>è®­ç»ƒé›†è®¾ç½®ï¼š<ul>
<li>VARIANCE: æ¯ç»„è®­ç»ƒé›†ä¸º10ä¸ªï¼Œä¸€å…±æœ‰100ç»„ï¼Œåˆ†åˆ«åšregressionï¼š</li>
<li>BIAS: æ¯ç»„è®­ç»ƒé›†ä¸º100ä¸ªï¼Œä¸€å…±æœ‰5000ä¸ªregression modelï¼š</li>
</ul>
</li>
<li>Colored curvesï¼š<ul>
<li>Red: <code>f *</code></li>
<li>Blue: avg(<code>f *</code>)= <code>f_</code></li>
<li>Black: (assumed) true <code>f^</code></li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Model</th>
<th>VARIANCE</th>
<th>BIAS</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>ç®€å•modelï¼šä¸€æ¬¡å¹‚<br>y = b + wx<sub>cp</sub></td>
<td><img src="linear.png" width="80%"></td>
<td><img src="linear1.png" width="80%"></td>
</tr>
<tr>
<td>ä¸‰æ¬¡å¹‚<br>y = b + w<sub>1</sub>x<sub>cp</sub>+w<sub>2</sub>(x<sub>cp</sub>)<sup>2</sup>+w<sub>3</sub>(x<sub>cp</sub>)<sup>3</sup></td>
<td><img src="power3.png" width="80%"></td>
<td><img src="power3_1.png" width="80%"></td>
</tr>
<tr>
<td>å¤æ‚modelï¼šäº”æ¬¡å¹‚<br>y = b + w<sub>1</sub>x<sub>cp</sub>+w<sub>2</sub>(x<sub>cp</sub>)<sup>2</sup>+w<sub>3</sub>(x<sub>cp</sub>)<sup>3</sup>+w<sub>3</sub>(x<sub>cp</sub>)<sup>4</sup>+w<sub>5</sub>(x<sub>cp</sub>)<sup>5</sup></td>
<td><img src="power5.png" width="80%"></td>
<td><img src="power5_1.png" width="80%"></td>
</tr>
</tbody>
</table>
</div>
<h3 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h3><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>ç®€å•model</th>
<th>å¤æ‚model</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Variance</strong></td>
<td>Varè¾ƒ<strong>å°</strong>ï¼Œè¡¨ç°ä¸ºæ”¶æ•›</td>
<td>Varè¾ƒ<strong>å¤§</strong>ï¼Œè¡¨ç°ä¸ºå‘æ•£</td>
</tr>
<tr>
<td>Solution</td>
<td></td>
<td>1. å¢åŠ data<br>ï¼ˆå¾ˆæœ‰æ•ˆæ§åˆ¶varçš„æ–¹æ³•ï¼Œä½†<strong>collect dataå¾ˆéš¾</strong>ï¼‰<br>2. æ­£åˆ™åŒ–regularization<br>ï¼ˆ+Î»Â·Î£(w<sub>i</sub>)<sup>2</sup> æ›²çº¿è¶Šå¹³æ»‘è¶Šå¥½ï¼Œä½†<strong>å¯èƒ½ä¼šä¼¤å®³bias</strong>ï¼‰</td>
</tr>
<tr>
<td><strong>Bias</strong></td>
<td>Biasè¾ƒ<strong>å¤§</strong>ï¼Œè¡¨ç°ä¸ºç¦»çœŸå®f^è¶Šè¿œ<br>ç®€å•modelèŒƒå›´å°å¯èƒ½æ ¹æœ¬æ²¡æœ‰åŒ…å«target</td>
<td>Biasè¾ƒ<strong>å°</strong>ï¼Œè¡¨ç°ä¸ºç¦»çœŸå®f^è¶Šè¿‘<br>ç®€å•modelèŒƒå›´å¤§åŒ…å«target</td>
</tr>
<tr>
<td>Solution</td>
<td>Redesign the model:<br>1. æ›´å¤šå‚æ•°<br>2. æ›´å¤šå¹‚æ¬¡</td>
</tr>
</tbody>
</table>
</div>
<p> é‚£ä¹ˆï¼Œåœ¨å›é¡¾ä¹‹å‰ä¸€è¯¾ä¸­erroråœ¨ç¬¬ä¸‰æ¬¡å¹‚ä¸­ä¼šçªç„¶è½¬å˜errorï¼Œéœ€è¦å¯¹errorè¿›è¡Œåˆ†ç±»ï¼š</p>
<ol>
<li><strong>çº¢</strong>çº¿æ˜¯biaså˜åŒ–ï¼Œ<strong>ç»¿</strong>çº¿æ˜¯varå˜åŒ–</li>
<li><p><strong>ä»å·¦åˆ°å³</strong>åˆ†åˆ«æ˜¯ <code>Underfitting: å¤§bias+å°vars</code> åˆ°<code>Overfitting: å°bias+å¤§vars</code></p>
<p><img src="errorClassification.png" width="80%"></p>
</li>
</ol>
<p>æ‰€ä»¥åœ¨åšå®Œmachine learningçš„æ—¶å€™ï¼Œéƒ½è¦é—®è‡ªå·±ï¼š<strong>åˆ°åº•æ˜¯biaså¤§è¿˜æ˜¯varå¤§ï¼Ÿ</strong></p>
<ul>
<li>å½“model<strong>æ— æ³•å»åˆtraining data</strong> â†’ biaså¤§ å³underfitting</li>
<li>å½“modelå»åˆtraining dataï¼Œå´åœ¨<strong>testing dataæœ‰å¾ˆå¤§error</strong> â†’ varå¤§ å³overfitting</li>
</ul>
<h2 id="3-Training-data-å’Œ-Testing-data-å¦‚ä½•åˆ†é…"><a href="#3-Training-data-å’Œ-Testing-data-å¦‚ä½•åˆ†é…" class="headerlink" title="3. Training data å’Œ Testing data å¦‚ä½•åˆ†é…"></a>3. Training data å’Œ Testing data å¦‚ä½•åˆ†é…</h2><ul>
<li>åŸºæœ¬äº‹å®<code>training set</code> â†’ <code>public testing set</code> â†’ <code>private testing set</code><br>training setè¾ƒå¥½çš„ï¼ˆerrorè¶Šå°çš„ï¼‰modelåœ¨public setä¸Šå¯èƒ½è¾ƒå¥½è¡¨ç°åï¼Œåœ¨private setçš„è¡¨ç°è¾ƒå·®ã€‚</li>
</ul>
<ol>
<li><p>æ³•1ï¼šCross Validation äº¤å‰æ ¡å‡†</p>
<ol>
<li>æŠŠtraining setåˆ†æˆä¸¤éƒ¨åˆ†ï¼š<br><code>TRAINING SET</code> = <code>Training set A</code> + <code>Validation set B</code> </li>
<li>åœ¨<code>Training set A</code>ä¸Štrainå®Œä¹‹åç”¨<code>Validation set B</code> å»é€‰æ‹©model</li>
<li>ä½†åŸæœ¬çš„training dataä¼šå› æ­¤å‡å°‘ï¼Œæ‰€ä»¥åœ¨æ­¥éª¤2ä¸­æœ€ç»ˆé€‰æ‹©å®Œäº†modelåï¼Œå†ç”¨å…¨éƒ¨çš„<code>TRAINING SET</code>åœ¨é€‰æ‹©å¥½çš„modelåŸºç¡€ä¸Šå†trainä¸€æ¬¡data</li>
<li>æ­¤æ—¶çš„public testing setå’Œprivate testing setçš„ç»“æœå¯ä»¥ç›¸è¿‘<br><strong>ä¸æ¨èï¼</strong> æŠŠpublic testing setå›å¤´æŠŠtraining setçš„å†æ ¡å‡†ä¸€æ¬¡ï¼Œè¿™æ ·åšä¼šæŠŠtesting setçš„biasåˆå¸¦åˆ°åŸæ¥çš„modelå»ã€‚åˆä¼šæŠŠpublic setæ ¡å‡†è¡¨ç°å¾—æ¯”private setå¥½ã€‚</li>
</ol>
</li>
<li><p>æ³•2ï¼šN-fold Cross Validation NæŠ˜äº¤å‰æ ¡å‡†</p>
</li>
</ol>
<p>æŠŠ<code>TRAINING SET</code>åˆ†æˆ N ç»„ï¼Œä¾‹å­å¦‚ä¸‹ï¼š<br>åˆ†ä¸‰ä»½ï¼Œä¸€ä»½validationï¼Œä¸¤ä»½trainingï¼Œåˆ†åˆ«ç»„åˆï¼š</p>
<p><code>TRAINING SET</code><br>1 <code>TR1</code> <code>TR2</code> <code>VAL</code> â†’ model 1, 2, 3,â€¦ â†“<br>2 <code>TR1</code> <code>VAL</code> <code>TR2</code> â†’ model 1, 2, 3,â€¦ â†“<br>3 <code>VAL</code> <code>TR1</code> <code>TR2</code> â†’ model 1, 2, 3,â€¦ â†“</p>
<p>â†’  ç›¸åŒmodelçš„avg error â†’ minimum</p>
<hr>
<h1 id="P6-æ¢¯åº¦ä¸‹é™-Gradient-Descent"><a href="#P6-æ¢¯åº¦ä¸‹é™-Gradient-Descent" class="headerlink" title="P6 æ¢¯åº¦ä¸‹é™ Gradient Descent"></a>P6 æ¢¯åº¦ä¸‹é™ Gradient Descent</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ht411g7Ef?p=6&amp;spm_id_from=pageDriver">Hung-yi Lee - Machine Learning 2017 - P6 æ¢¯åº¦ä¸‹é™</a></p>
<blockquote>
<p><strong>Recap from P3</strong><br>Gradient Descent: Î¸*  = arg min<sub>Î¸</sub> L(Î¸)<br>L for Loss function, Î¸ for parameters (ä¸€ç»„å‚æ•°ï¼Œn â‰¥1)</p>
</blockquote>
<p>å‡è®¾ï¼šÎ¸ æœ‰ä¸¤ä¸ªå˜é‡ {Î¸<sub>1</sub>, Î¸<sub>2</sub>}<br>ä¸”æœ‰ï¼š<br>a. Gradient function <em>âˆ‡ L(Î¸) =</em> [ ğœ•L(Î¸<sub>1</sub>)/ğœ•Î¸<sub>1</sub>, ğœ•L(Î¸<sub>2</sub>)/ğœ•Î¸<sub>2</sub> ]<sup>T</sup> ï¼Œå…¶è¡¨è¾¾ä¸ºä¸€ä¸ªvector<br>b. learning rate <em>Î·</em><br>åˆ™ Gradient Descent å¯è¡¨è¾¾ä¸ºï¼š</p>
<blockquote>
<p>Î¸<sup>1</sup> = Î¸<sup>0</sup> - Î· <em> âˆ‡ L(Î¸<sup>0</sup>)<br>Î¸<sup>2</sup> = Î¸<sup>1</sup> - Î· </em> âˆ‡ L(Î¸<sup>1</sup>)<br>â€¦until find the minimum</p>
</blockquote>
<p><em>Î¸<sup>i</sup> = Î¸<sup>i-1</sup> - Î· </em> âˆ‡ L(Î¸<sup>i-1</sup>)*</p>
<hr>
<p>Q: å¦‚ä½•æé«˜trainingé€Ÿåº¦ï¼Ÿ</p>
<h2 id="TIP-1-Learning-Rate"><a href="#TIP-1-Learning-Rate" class="headerlink" title="TIP 1:  Learning Rate:"></a>TIP 1:  Learning Rate:</h2><p>ç”¨ Update amount - Loss åˆ¶å›¾ï¼ŒåšLRçš„å¯è§†åŒ–ï¼Œç†è§£LRæ˜¯æ€ä¹ˆè°ƒå‚çš„ã€‚</p>
<blockquote>
<p>å¦‚æœåœ¨åšgradient descentçš„æ—¶å€™åº”è¯¥æŠŠè¿™ä¸ªå›¾ç”»å‡ºæ¥ï¼Œå»ç†è§£å‰å‡ æ¬¡updateçš„æ—¶å€™åˆ°åº•learning rateæ˜¯æ€ä¹ˆè°ƒå‡ºæ¥ï¼›è¦ç¡®å®šå®ƒæ˜¯<strong>ç¨³å®šçš„ä¸‹é™</strong></p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="LR1.png" width="80%" align="center"></th>
<th style="text-align:center"><img src="LR1-charts.png" width="80%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">å®é™…æ›²çº¿æ‰¾æ¢¯åº¦</td>
<td style="text-align:center">visualization</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Adaptive-Learning-Rates"><a href="#Adaptive-Learning-Rates" class="headerlink" title="Adaptive Learning Rates"></a>Adaptive Learning Rates</h3><p>åŸºæœ¬åŸåˆ™ï¼šlearning rateéšç€å‚æ•°çš„updateï¼Œä¼šè¶Šæ¥è¶Šå°</p>
<ul>
<li>åœ¨åˆšå¼€å§‹èµ·å§‹ç‚¹çš„æ—¶å€™ï¼Œç¦»æœ€ä½ç‚¹æ˜¯æœ€è¿œï¼Œæ‰€ä»¥ä¸€å¼€å§‹çš„æ­¥ä¼ä¼šå¾ˆå¤§</li>
<li>ç»è¿‡å¥½å‡ æ¬¡å‚æ•°çš„updateä¹‹åï¼Œæ¯”è¾ƒé è¿‘ç›®æ ‡äº†ï¼Œå°±åº”è¯¥è°ƒå°LR</li>
<li>e.g: 1/t decay: <em>Î·<sup>t</sup> = Î·/(t+1)<sup>1/2</sup></em></li>
</ul>
<h4 id="Adagradæ˜¯å…¶ä¸­æœ€basicçš„å°æŠ€å·§çš„adaptive-æ–¹å¼"><a href="#Adagradæ˜¯å…¶ä¸­æœ€basicçš„å°æŠ€å·§çš„adaptive-æ–¹å¼" class="headerlink" title="Adagradæ˜¯å…¶ä¸­æœ€basicçš„å°æŠ€å·§çš„adaptive æ–¹å¼"></a>Adagradæ˜¯å…¶ä¸­æœ€basicçš„å°æŠ€å·§çš„adaptive æ–¹å¼</h4><ul>
<li>Conceptï¼š<em>æ¯ä¸ªå‚æ•°çš„LRé™¤ä»¥<strong>ä¹‹å‰å¾®åˆ†å€¼çš„root mean square</strong></em></li>
<li>å…·ä½“åšæ³•ï¼š</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><em>prerequisite</em></td>
<td>åå¾®åˆ† g<sup>t</sup> =ğœ• L(Î¸<sup>t</sup>)/ğœ•w<br>å‰æ‰€æœ‰åå¾®åˆ†å‚æ•°çš„å‡æ–¹æ ¹ <strong>Ïƒ<sup>t</sup></strong>= [1/(t+1))Î£(g<sup>i</sup>)]<sup>2</sup>)<sup>1/2</sup><br>ï¼ˆå¯¹æ¯ä¸ªå‚æ•°éƒ½æ˜¯ç‹¬ç«‹ä¸ä¸€è‡´çš„ï¼‰</td>
</tr>
<tr>
<td>Vanilla Gradient Descent<br><strong>Adagrad</strong></td>
<td><em>w<sup>t+1</sup> = w<sup>t</sup> - Î·<sup>t</sup>g<sup>t</sup></em><br><em>w<sup>t+1</sup> = w<sup>t</sup> - Î·<sup>t</sup> <strong>/Ïƒ<sup>t</sup></strong> g<sup>t</sup></em></td>
</tr>
</tbody>
</table>
</div>
<p>è€Œ1/t decay: <em>Î·<sup>t</sup> = Î·/(t+1)<sup>1/2</sup></em>ï¼Œ æ‰€ä»¥å¼ä¸­ <em>1/(t+1)<sup>1/2</sup></em> ç›¸æ¶ˆï¼š ç®€åŒ–æˆ </p>
<ul>
<li><em>w<sup>t+1</sup> = w<sup>t</sup> - Î·<sup>t</sup> <strong>/Ïƒ<sup>t</sup></strong> g<sup>t</sup> <br> = w<sup>t</sup> -  Î· <strong>/(Î£(g<sup>i</sup>)<sup>2</sup>) <sup>1/2</sup></strong> g<sup>t</sup></em> </li>
</ul>
<p>æ¥è‡ªæè€å¸ˆçš„çµé­‚æ‹·é—®ï¼š</p>
<blockquote>
<p>æ€ä¹ˆè§£é‡Šï¼šgradientè¶Šå¤§ï¼Œ<em>g<sup>t</sup></em> é¡¹ï¼Œstepè¶Šå¤§ï¼›åŒæ—¶ 1/(Î£(g<sup>i</sup>)<sup>2</sup>) <sup>1/2</sup> é¡¹ï¼Œstepè¶Šå°ï¼Ÿ</p>
</blockquote>
<ul>
<li>è§£é‡Šaï¼šåå·®</li>
<li>è§£é‡Šbï¼šæ‰¾å¾®åˆ†æœ€å°å€¼ = æ¢¯åº¦ä¸‹é™çš„ç›®çš„ = å¾®åˆ†é«˜æ—¶ï¼Œstepé•¿ï¼›å¾®åˆ†ä½æ—¶ï¼ŒstepçŸ­<br>ä»¥ç®€å•äºŒå…ƒå‡½æ•° y = ax<sup>2</sup> + bx + cä¸ºä¾‹ï¼š<br><br><img src="adagrad1.png" width="60%"><br><br>1. æ¢¯åº¦æœ€ä½ä½ç½®ï¼Œä¸€æ¬¡å¾®åˆ†ä¸ºé›¶ï¼Œå³ï¼š|ğœ• y/ğœ• x| = |2ax+b| = 0, x = -b/2a<br><br>2. è‹¥ä»x<sub>0</sub>åˆ°æ¢¯åº¦æœ€ä½çš„å°±æ˜¯è·ç¦»å°±æ˜¯ï¼š|x<sub>0</sub> - (-b/2a)| = |x<sub>0</sub> +b/2a| = |2ax<sub>0</sub>+b|/2a<br><br>3. åŒæ—¶ï¼š |2ax<sub>0</sub>+b|/2a  = |ğœ• y/ğœ• x|<sub>x=x0</sub> / |ğœ•â€™â€™ y/ğœ•â€™â€™ x| = ä¸€æ¬¡å¾®åˆ†åœ¨x<sub>0</sub>çš„è§£/äºŒæ¬¡å¾®åˆ†ï¼ˆå½“åªæœ‰ä¸€ç»„å‡½æ•°æ—¶å¯åªçœ‹ä¸€æ¬¡å¾®åˆ†éƒ¨åˆ†ï¼‰<br><br>4. å’Œ Adagrad çš„å…³ç³»ï¼šg<sup>t</sup>/(Î£(g<sup>i</sup>)<sup>2</sup>) <sup>1/2</sup> ç›¸å½“äº ä¸€æ¬¡å¾®åˆ†/äºŒæ¬¡å¾®åˆ†ã€‚<br> 4.1 root mean squareçš„æ–¹æ³•è¡¨è¾¾äº†è¯¥ä¸€æ¬¡å¾®åˆ†çš„å¼€åˆç¨‹åº¦ï¼Œåœ¨è¿™é‡Œå¯è¿‘ä¼¼äºäºŒæ¬¡å¾®åˆ†çš„ä½œç”¨ã€‚<br>4.2 å½“è®­ç»ƒé›†è¿‡å¤§ç­‰åŸå› ï¼Œç®—ä¸€æ¬¡å¾®åˆ†å¯èƒ½å°±èŠ±è´¹äº†ä¸€å¤©ï¼Œå†äºŒæ¬¡å¾®åˆ†ä¼šèŠ±è´¹ç›¸å¯¹çš„æ—¶é—´ï¼Œæ­¤æ—¶åˆ©ç”¨root mean squareå¯ç›´æ¥è®¡ç®—ä¸€æ¬¡å¾®åˆ†ç»“æœå¹¶è¿‘ä¼¼ç±»æ¯”ï¼š|ğœ•â€™â€™ y/ğœ•â€™â€™ x|â‰ˆ(Î£(g<sup>i</sup>)<sup>2</sup>) <sup>1/2</sup><br><img src="adagrad2.png" width="60%"></li>
</ul>
<hr>
<h2 id="TIP-2-STOCHASTIC-GRADIENT-DESCENT-éšæœºæ¢¯åº¦ä¸‹é™"><a href="#TIP-2-STOCHASTIC-GRADIENT-DESCENT-éšæœºæ¢¯åº¦ä¸‹é™" class="headerlink" title="TIP 2:  STOCHASTIC GRADIENT DESCENT éšæœºæ¢¯åº¦ä¸‹é™"></a>TIP 2:  STOCHASTIC GRADIENT DESCENT éšæœºæ¢¯åº¦ä¸‹é™</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="stochasticGD1.png" width="70%"></th>
<th style="text-align:center"><img src="stochasticGD2.png" width="70%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">çœ‹å®Œæ‰€æœ‰å‚æ•°åå†å¼€å§‹è®¡ç®—</td>
<td style="text-align:center">éšæœºé€‰æ‹©å‚æ•°åï¼Œç›´æ¥è®¡ç®—</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="TIP-3-FEATURE-SCALING-ç‰¹å¾ç¼©æ”¾"><a href="#TIP-3-FEATURE-SCALING-ç‰¹å¾ç¼©æ”¾" class="headerlink" title="TIP 3: FEATURE SCALING ç‰¹å¾ç¼©æ”¾"></a>TIP 3: FEATURE SCALING ç‰¹å¾ç¼©æ”¾</h2><p><code>example:</code> æŠŠx<sub>1</sub>å’Œx<sub>2</sub>æ”¾åœ¨ç›¸åŒscaleä¸Š</p>
<ul>
<li><img src="featureScaling.png" width="80%"><br><br>ä½¿å¾—æ­¤ä¾‹ä¸­w<sub>1</sub>å’Œw<sub>2</sub>æ›´è¿‘ä¼¼åœ†å½¢ï¼Œè®©æ±‚å¾®åˆ†æ›´å¿«ï¼ˆç›´æ¥å‘åœ†å¿ƒèµ°ï¼‰<br><br><img src="featureScaling_LOSS.png" width="80%"><br><br><em>å®ç°Feature Scalingçš„æ–¹æ³•æœ‰å¾ˆå¤š</em></li>
</ul>
<hr>
<h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>æ³°å‹’å±•å¼€å¼ï¼Œåªè€ƒè™‘åŸå¼+ä¸€æ¬¡å¾®åˆ†ï¼ˆapproximation ï¼‰<br>h(x) = h(x<sub>0</sub>) +hâ€™(x<sub>0</sub>)(x-x<sub>0</sub>)+<del>hâ€™â€™(x<sub>0</sub>)/2!â€¦</del><br>åŸå› ï¼š<br>1. è¿™ç§å¤§çº¦æ¥è¿‘å·²ç»å¤Ÿç”¨<br>2. äºŒæ¬¡å¾®åˆ†åœ¨deep learningä¼šå¢åŠ æ—¶é—´ï¼Œä¸åˆ’ç®—<br><strong>ä¸€å¥è¯æ€»ç»“</strong>ï¼šé€šè¿‡å„é¡¹åå¯¼ç»„æˆvectorï¼Œå¹¶ç‚¹ä¹˜æ±‚æœ€å°å€¼å³180Â°å¹³è¡Œæ—¶ï¼›å…¶ä¸­learning rateæ­£æ¯”äºé€‰ç‚¹åœ†å‹åŠå¾„ï¼Œå¹¶èµ‹è´Ÿå·å½¢æˆ180Â°ï¼›ä¸”ç”»åœ†æ—¶åŠå¾„è¶Šå°è¶Šç²¾ç¡®ã€‚</p>
<hr>
<h1 id="P7-æ¢¯åº¦ä¸‹é™-Gradient-Descent-AOEæ¼”ç¤º"><a href="#P7-æ¢¯åº¦ä¸‹é™-Gradient-Descent-AOEæ¼”ç¤º" class="headerlink" title="P7 æ¢¯åº¦ä¸‹é™ Gradient Descent -  AOEæ¼”ç¤º"></a>P7 æ¢¯åº¦ä¸‹é™ Gradient Descent -  AOEæ¼”ç¤º</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ht411g7Ef?p=7">Hung-yi Lee - Machine Learning 2017 - P7 æ¢¯åº¦ä¸‹é™ AOE</a></p>
<hr>
<h1 id="P8-æ¢¯åº¦ä¸‹é™-Gradient-Descent-Minecraftæ¼”ç¤º"><a href="#P8-æ¢¯åº¦ä¸‹é™-Gradient-Descent-Minecraftæ¼”ç¤º" class="headerlink" title="P8 æ¢¯åº¦ä¸‹é™ Gradient Descent -  Minecraftæ¼”ç¤º"></a>P8 æ¢¯åº¦ä¸‹é™ Gradient Descent -  Minecraftæ¼”ç¤º</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ht411g7Ef?p=8">Hung-yi Lee - Machine Learning 2017 - P8 æ¢¯åº¦ä¸‹é™ AOE</a></p>
 <p id="task04"></p>
<p align="center">- - - - - - - - - - - - - - - T A S K 0 4 - - - - - - - - - - - - - - -<br><a href="#index">[ B A C K ]</a></p>

<p><img src="HUNGYILEE_04.png" width="100%"></p>
<p align="center"> </p>

<h1 id="P13-Deep-Learning"><a href="#P13-Deep-Learning" class="headerlink" title="P13 Deep Learning"></a>P13 Deep Learning</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ht411g7Ef?p=13">Hung-yi Lee - Machine Learning 2017 - P13 æ·±åº¦å­¦ä¹ </a></p>
<hr>
<h2 id="THREE-STEPS-FOR-DEEP-LEARNING"><a href="#THREE-STEPS-FOR-DEEP-LEARNING" class="headerlink" title="THREE STEPS FOR DEEP LEARNING"></a>THREE STEPS FOR DEEP LEARNING</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Step 1</th>
<th>Step 2</th>
<th>Step 3</th>
</tr>
</thead>
<tbody>
<tr>
<td>Define a function set</td>
<td>Goodness of function</td>
<td>Pick the best function</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Step-1-Define-function"><a href="#Step-1-Define-function" class="headerlink" title="Step 1 : Define function"></a>Step 1 : Define function</h3><ul>
<li>è¿™ä¸ªfunctionä¹Ÿå°±æ˜¯ç¥ç»ç½‘ç»œNeural Networkã€‚</li>
</ul>
<h4 id="1-1-Neural-Network-æ˜¯ä»€ä¹ˆï¼Ÿ"><a href="#1-1-Neural-Network-æ˜¯ä»€ä¹ˆï¼Ÿ" class="headerlink" title="1.1 Neural Network æ˜¯ä»€ä¹ˆï¼Ÿ"></a>1.1 Neural Network æ˜¯ä»€ä¹ˆï¼Ÿ</h4><p>ç”±ä¸åŒçš„logistic regressionè¿æ¥ï¼ˆconcatenateï¼‰åœ¨ä¸€èµ·ï¼ŒæŠŠå…¶ä¸­ä¸€ä¸ªlogistic regressionç§°ä¹‹ä¸ºç¥ç»å…ƒNeuronã€‚</p>
<h4 id="1-2-ç¥ç»å…ƒ-Neuron-ä¸­ï¼š"><a href="#1-2-ç¥ç»å…ƒ-Neuron-ä¸­ï¼š" class="headerlink" title="1.2 ç¥ç»å…ƒ Neuron ä¸­ï¼š"></a>1.2 ç¥ç»å…ƒ Neuron ä¸­ï¼š</h4><ol>
<li>Network <strong>structures</strong>: ä¸åŒçš„è¿æ¥ã€‚ä¸åŒäºregressionä¸éœ€è€ƒè™‘structureï¼Œç¥ç»ç½‘ç»œä¸­çš„structure(æœ‰å¤šå°‘å±‚layerï¼Œæ¯å±‚layeræœ‰å¤šå°‘neuronç­‰)å¾ˆé‡è¦</li>
<li>Network <strong>parameter</strong> <em>Î¸</em>: å¤§å †logistic regressionçš„weightå’Œbiasé›†åˆèµ·æ¥</li>
</ol>
<h4 id="1-3-neuroné—´æ€ä¹ˆè¿æ¥ï¼Ÿ"><a href="#1-3-neuroné—´æ€ä¹ˆè¿æ¥ï¼Ÿ" class="headerlink" title="1.3 neuroné—´æ€ä¹ˆè¿æ¥ï¼Ÿ"></a>1.3 neuroné—´æ€ä¹ˆè¿æ¥ï¼Ÿ</h4><ol>
<li>æœ€å¸¸è§çš„ç§°ä½œï¼šFully Connect Feedforward Network<ol>
<li>æŠŠç¥ç»å…ƒæ’æˆä¸€æ’ä¸€æ’</li>
<li>æ¯ä¸ªneuronéƒ½æœ‰ä¸€ç»„weightå’Œbiasï¼Œé€šè¿‡training dataæ‰¾å‡ºæ¥</li>
</ol>
</li>
<li>æ•´ä¸ªprocessï¼š<br>  <code>input</code> â†’ <code>matrixè¿ç®—</code> (diff. weight &amp; bias) â†’ <code>logistic regression(sigmoid function)</code> â†’ é‡å¤äºä¸åŒlayer â†’ <code>output</code><br>  inputæ˜¯ä¸€ä¸ªvectorï¼Œoutputä¹Ÿä¼šæ˜¯ä¸€ä¸ªvector<br> ç»™å®šçš„ç»“æ„ = define a function set</li>
</ol>
<h4 id="1-4-Fully-Connect-Feedforward-Network"><a href="#1-4-Fully-Connect-Feedforward-Network" class="headerlink" title="1.4 Fully Connect Feedforward Network"></a>1.4 Fully Connect Feedforward Network</h4><ol>
<li>layerå’Œlayerä¹‹é—´ä¸¤ä¸¤ç›¸è¿ï¼Œæ‰€ä»¥ç§°ä¹‹ä¸ºfully connect</li>
<li>ä»layer1ä¼ åˆ°layer2ï¼Œç”±åå¾€å‰ä¼ ï¼ˆæ­¤å¤„ <strong>å</strong>æŒ‡layeræ•°å­—æ›´å°ï¼Œå³<u>è¿œç¦»outputç«¯</u>ä¸º<strong>å</strong>ï¼Œé è¿‘<u>outputç«¯</u>ä¸º<strong>å‰</strong>ï¼‰</li>
<li><code>Input Layer</code> â†’ <code>Hidden Layers</code> â†’ <code>Output Layer</code><br> é‚£Deep Learningä¸­çš„ Deep = Many <code>Hidden Layers</code>ã€‚</li>
</ol>
<h4 id="1-5-Networkçš„è¿ä½œï¼šMartix-Operation"><a href="#1-5-Networkçš„è¿ä½œï¼šMartix-Operation" class="headerlink" title="1.5 Networkçš„è¿ä½œï¼šMartix Operation"></a>1.5 Networkçš„è¿ä½œï¼šMartix Operation</h4><p align="center"><img src="operation.png" width="50%"><br><img src="operation2.png" width="50%"></p>

<ol>
<li>blue: <code>input</code> = vector</li>
<li>yellow: <code>weight</code> = matrix</li>
<li>green: <code>bias</code> = vector</li>
<li>blue: <code>output</code> = logistic regression, å¯ä»¥æ˜¯sigmoid, ä½†ç°åœ¨å¹¶ä¸å¸¸ç”¨ </li>
</ol>
<h4 id="1-6-Output-layer"><a href="#1-6-Output-layer" class="headerlink" title="1.6 Output layer"></a>1.6 Output layer</h4><ol>
<li>Output Layerä¹‹å‰çš„éƒ¨åˆ†çœ‹ä½œæ˜¯ç‰¹å¾å€¼æå–å™¨ï¼ˆfeature extractorï¼‰ï¼Œä»£æ›¿ç‰¹å¾å·¥ç¨‹ï¼ˆfeature engineeringï¼‰</li>
<li>Output Layerä¸ºå¤šçº§åˆ†ç¦»å™¨ï¼ˆmulti-class classifierï¼‰<br> ç›¸å½“äºå‰é¢<code>Hidden Layers</code> ä¸­æŠ½å‡ºä¸€ç»„ç‰¹åˆ«å¥½çš„featureï¼Œå¹¶ç”¨multi-class classifieråˆ†ç±»å¥½ï¼Œç”¨softmax functionã€‚</li>
</ol>
<h4 id="1-7-Structure"><a href="#1-7-Structure" class="headerlink" title="1.7 Structure"></a>1.7 Structure</h4><ol>
<li>å¤šå°‘å±‚ï¼Ÿå¤šå°‘ç¥ç»å…ƒï¼Ÿ<br> å¤šå°è¯•+ç›´è§‰ï¼ˆç»éªŒï¼‰</li>
<li>ç»“æ„è‡ªåŠ¨ç”Ÿæˆï¼šEvolutionary Artificial Neural Networks</li>
<li>è‡ªå·±è®¾è®¡ç»“æ„ï¼šCNN Convolutional Neural Network</li>
</ol>
<h3 id="Step-2-Goodness-of-function"><a href="#Step-2-Goodness-of-function" class="headerlink" title="Step 2 : Goodness of function"></a>Step 2 : Goodness of function</h3><p>outputä¸ºyï¼Œtargetä¸ºy^ï¼Œç›®æ ‡å°±æ˜¯y,y^ è¶Šå°è¶Šå¥½ã€‚</p>
<p>Total Loss: L = Î£ C<sup>n</sup>(Î¸) å³æ‰€æœ‰lossçš„æ€»æŸå¤±æœ€å°‘ã€‚<br>â†’ gradient descent â†’ network parameter Î¸è°ƒæ•´</p>
<ul>
<li>Backpropagationï¼šåå‘ä¼ æ’­æœ‰æ•ˆè®¡ç®—wå¯¹Lçš„å¾®åˆ†<br>  æœ‰ä»¥ä¸‹toolkitï¼š<p align="center"><img src="bp.png" width="80%"></p>

</li>
</ul>
<h3 id="Step-3-Pick-the-best-function"><a href="#Step-3-Pick-the-best-function" class="headerlink" title="Step 3 : Pick the best function"></a>Step 3 : Pick the best function</h3><hr>
<h1 id="P14-Backpropagation"><a href="#P14-Backpropagation" class="headerlink" title="P14 Backpropagation"></a>P14 Backpropagation</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ht411g7Ef?p=14">Hung-yi Lee - Machine Learning 2017 - P14 åå‘ä¼ æ’­</a></p>
<h3 id="Chain-Rule"><a href="#Chain-Rule" class="headerlink" title="Chain Rule"></a>Chain Rule</h3><p> é€šè¿‡å¾®åˆ†æˆ–åå¾®åˆ†çš„åˆ†è£‚ï¼ŒæŠŠåˆå§‹å‡½æ•°å’Œç›®æ ‡å‡½æ•°å¯¹åº”ã€‚</p>
<ul>
<li>Case 1. ä¸²è”ï¼š <em>y = g(x), z = h(y)</em><br> Î”<em>x</em> â†’  Î”<em>y</em> â†’ Î”<em>z</em> <ul>
<li>Case 2. ä¸²è”ï¼š <em>x = g(s), y=h(s), z = k(x,y)</em><br>Î”<em>s</em> â†’  Î”<em>x</em> â†’ Î”<em>z</em><br>Î”<em>s</em> â†’ Î”<em>y</em> â†’ Î”<em>z</em>  </li>
</ul>
</li>
</ul>
<h3 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h3><ol>
<li><p>æ±‚Loss function L(Î¸) = Î£C<sup>n</sup>(Î¸) å¯¹wçš„åå¯¼ï¼š<br>ğœ•L(Î¸)/ğœ•w = Î£ ğœ•C<sup>n</sup>(Î¸)/ğœ•w</p>
</li>
<li><p>å±•å¼€åï¼š<br>ğœ•C/ğœ•w = (ğœ•z/ğœ•w) * (ğœ•C/ğœ•z)<br>å…¶ä¸­å‰é¡¹ï¼š<code>ğœ•z/ğœ•w</code> = x (inputé¡¹)ï¼Œå› ä¸ºz = x<sub>1</sub>w<sub>1</sub>+x<sub>2</sub>w<sub>2</sub>+â€¦+b<br>ä¹Ÿå°±æ˜¯å¯ä»¥ç”¨Forward pathæ­£å‘è®¡ç®—åå¾®åˆ†ã€‚</p>
</li>
<li><p>ä½†æ˜¯ï¼šå±•å¼€å¼åé¡¹ <code>ğœ•C/ğœ•z</code> å¾ˆéš¾ç®—ï¼Œæ‰€ä»¥ç”¨Backward pathæ¥ç®—ã€‚å…¶è¿‡ç¨‹ç›¸å½“äºç”µè·¯ä¸­æ”¾å¤§å™¨çš„åšæ³•ã€‚</p>
</li>
<li><p>backward pathçš„éœ€è¦æ­£å‘ç®—å®Œï¼Œå¾—å‡ºoutputåï¼Œå†åå‘ç®—å¾—åå¯¼ã€‚</p>
<p id="task05"></p>
<p align="center">- - - - - - - - - - - - - - - T A S K 0 5 - - - - - - - - - - - - - - -<br><a href="#index">[ B A C K ]</a></p>

</li>
</ol>
<p><img src="HUNGYILEE_05.png" width="100%"></p>
<p align="center"></p>

<h1 id="P5-Local-minima-vs-Saddle-point"><a href="#P5-Local-minima-vs-Saddle-point" class="headerlink" title="P5 Local minima vs Saddle point"></a>P5 Local minima vs Saddle point</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11K4y1S7AD?p=5">Hung-yi Lee - Machine Learning 2021 - P5 å±€éƒ¨æœ€å°ä¸éç‚¹</a></p>
<hr>
<h2 id="1-Terminology-of-local-minima-amp-saddle-point"><a href="#1-Terminology-of-local-minima-amp-saddle-point" class="headerlink" title="1. Terminology of local minima &amp; saddle point"></a>1. Terminology of <u>local minima</u> &amp; <u>saddle point</u></h2><h3 id="Optimization-fails-â†“"><a href="#Optimization-fails-â†“" class="headerlink" title="Optimization fails â†“"></a>Optimization fails â†“</h3><p><P align="center"><img src="LossGraph.png" width="80%">&lt;/p&gt;</p>
<p><strong>Scenarios</strong></p>
<pre><code>1. `Blue`ï¼šå½“åˆ°è¾¾æŸä¸ªæ—¶åˆ»ï¼Œå‚æ•°updateå¯¹lossæ²¡æœ‰å˜åŒ–ï¼Œä½†losså¹¶ä¸å°ï¼›
2. `Orange`ï¼šä»åˆšä¸€å¼€å§‹ï¼Œgradientå°±æ²¡æœ‰å˜åŒ–ï¼Œgradientä¸º0
</code></pre><p>å³ <em>å¯¹Lossçš„å¾®åˆ†ä¸º0ï¼Œgradient descentæ— æ³•updateå‚æ•°ã€‚</em> <strong>å¯èƒ½çš„åŸå› </strong>ï¼š</p>
<pre><code>1. `local minima` 
2. `saddle point`ï¼ˆéç‚¹ï¼‰â†’ æ—¢ä¸æ˜¯local minima, åˆä¸æ˜¯local maxima
</code></pre><p align="center"><img src="localMinima+saddlePoint.png" width="80%"></p>

<ul>
<li>gradient = 0çš„ç‚¹ ç»Ÿç§°ä¸º <code>critical point</code></li>
</ul>
<hr>
<h2 id="2-å¦‚ä½•åˆ¤æ–­local-minimaè¿˜æ˜¯saddle-pointï¼Ÿ"><a href="#2-å¦‚ä½•åˆ¤æ–­local-minimaè¿˜æ˜¯saddle-pointï¼Ÿ" class="headerlink" title="2. å¦‚ä½•åˆ¤æ–­local minimaè¿˜æ˜¯saddle pointï¼Ÿ"></a>2. å¦‚ä½•åˆ¤æ–­local minimaè¿˜æ˜¯saddle pointï¼Ÿ</h2><ul>
<li><p>Task03ä¸­çš„æ³°å‹’å±•å¼€å¼ï¼Œå¢åŠ äºŒæ¬¡å¾®åˆ†é¡¹</p>
<ol>
<li><em>Î¸ = Î¸â€™</em> é™„è¿‘çš„ L(Î¸) å¯å±•å¼€ä¸ºï¼š<p align="center"> *L(Î¸) â‰ˆ L(Î¸') + ( Î¸ - Î¸' )<sup>T</sup> **g** + 1/2 ( Î¸ - Î¸' )<sup>T</sup> **H** ( Î¸ - Î¸' )* </p><ol>
<li>ä¸€æ¬¡å¾®åˆ† Gradient <strong><em>g</em></strong> is a vectorï¼š<strong>*g</strong><sub>i</sub> = ğœ• L(Î¸â€™)/ ğœ• Î¸<sub>i</sub>*</li>
<li>äºŒæ¬¡å¾®åˆ† Hessian <strong>H</strong> is a matrixï¼š<strong>*H</strong><sub>ij</sub> = ğœ• <sup>2</sup>L(Î¸â€™)/ ğœ• Î¸<sub>i</sub>ğœ• Î¸<sub>j</sub>*</li>
</ol>
</li>
<li>å’Œ<code>critical point</code>æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ<ol>
<li>ä¸€æ¬¡å¾®åˆ†åœ¨<code>critical point</code>æ—¶ä¸º<strong>é›¶</strong></li>
<li>äºŒæ¬¡å¾®åˆ†åˆ™å¯ç”¨äºåˆ¤åˆ«<code>critical point</code>çš„ç‰¹æ€§ï¼ˆä»–çš„åœ°è²Œé•¿ä»€ä¹ˆæ ·å­ï¼‰</li>
</ol>
</li>
<li><p>Hessian <strong>H</strong>ï¼šsimplified 1/2 ( Î¸ - Î¸â€™ )<sup>T</sup> <strong>H</strong> ( Î¸ - Î¸â€™ )<em> â†’ v<sup>T</sup> <em>*H</em></em> v</p>
<ol>
<li>For all <code>v</code>:  v<sup>T</sup> <strong>H</strong> v &gt;0 â†’ Î¸â€™ é™„è¿‘ L(Î¸) &gt; L(Î¸â€™) â†’ <u><strong>Local minima</strong></u></li>
<li>For all <code>v</code>:  v<sup>T</sup> <strong>H</strong> v <0 â†’ Î¸' é™„è¿‘ L(Î¸) < L(Î¸') â†’ <u><strong>Local maxima</strong>&lt;/u&gt;</li>
<li>Sometimes v<sup>T</sup> <strong>H</strong> v &gt;0, sometimes v<sup>T</sup> <strong>H</strong> v <0 â†’  <u> <strong>Saddle point</strong> &lt;/u&gt;</li>
</ol>
<ul>
<li>v<sup>T</sup> <strong>H</strong> v &gt;0 ç›¸å½“äº <code>H</code> is positive definite = All eigen values are <strong>positive</strong>ï¼Œå³ç›´æ¥çœ‹Hçš„eigenvalueä¸ºæ­£å°±å¯ä»¥åˆ¤æ–­local minimaï¼›åŒç†eigenvalueå…¨è´Ÿæ—¶ï¼Œä¸ºlocal maximaï¼›æœ‰æ­£æœ‰è´Ÿæ—¶ï¼Œä¸ºsaddle pointã€‚</li>
</ul>
</li>
<li><code>Saddle point</code>æ—¶æ€ä¹ˆç»§ç»­åšgradient descentï¼š<ul>
<li>ä»¥ä¸‹æ–¹æ³•ä¸å¸¸åœ¨å®é™…ä¸­è¿è¡Œï¼š<ol>
<li>æ±‚<code>H</code>çš„ç‰¹å¾å‘é‡<strong>u</strong>åŠç‰¹å¾å€¼Î» â†’ v<sup>T</sup> <strong>H</strong>v ä¸­<strong>v</strong>ç”¨<strong>u</strong>ä»£æ›¿ â†’ u<sup>T</sup> <strong>H</strong> u = u<sup>T</sup> Î» u = Î» ||<strong>u</strong>||<sup>2</sup></li>
<li>è‹¥ Î» &lt; 0 æ—¶ï¼ŒÎ» ||u||<sup>2</sup> &lt; 0 â†’ L(Î¸) &lt; L(Î¸â€˜) å³ local maximaçš„æƒ…å†µ</li>
<li>æ¢å¥è¯è¯´ åªè¦æ²¿ç€eigenvector <strong>u</strong> çš„æ–¹å‘å»æ›´æ–°å‚æ•°ï¼ŒL å°±ä¼šå‡å°</li>
<li>ä½†ç”±äºè®¡ç®—é‡è¿‡å¤§ï¼Œè¿™ç§æ–¹æ³•ä¸å®ç”¨ã€‚ä½†æ˜¯æ˜¯ä¸€ç§å¯èƒ½æ€§ï¼Œå®åœ¨ç¢°åˆ°saddle pointæœ€å·®çš„æƒ…å†µä¸‹ä¹Ÿèƒ½ç”¨è¿™ç§æ–¹å¼ã€‚</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<hr>
<h1 id="P6-Batch-vs-Momentum"><a href="#P6-Batch-vs-Momentum" class="headerlink" title="P6 Batch vs Momentum"></a>P6 Batch vs Momentum</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11K4y1S7AD?p=6">Hung-yi Lee - Machine Learning 2021 - P6 æ‰¹æ¬¡ä¸åŠ¨é‡</a></p>
<hr>
<h2 id="1-BATCH"><a href="#1-BATCH" class="headerlink" title="1. BATCH"></a>1. BATCH</h2><ol>
<li><p>Terminology</p>
<ul>
<li>batch<ul>
<li>Batchä¹Ÿæœ‰äººç§°ä¹‹ä¸ºmini batch</li>
<li>å®é™…ä¸Šç®—å¾®åˆ†çš„æ—¶å€™ï¼ŒæŠŠæ‰€æœ‰dataåˆ†æˆä¸€ä¸ªä¸ªçš„batch</li>
<li>æ¯ä¸€ç¬”batchèµ„æ–™é‡Œç®—gradientï¼Œå†updateå‚æ•°</li>
<li>æ„æ€æ˜¯ä¸ä¼šæŠŠæ‰€æœ‰çš„dataåŒæ—¶ç®—lossï¼Œè€Œæ˜¯æŒ‰batchæ¥</li>
</ul>
</li>
<li>epoch<ul>
<li>æŠŠæ‰€æœ‰çš„batchçœ‹è¿‡ä¸€éï¼Œç§°ä¹‹ä¸ºä¸€ä¸ªepoch</li>
<li>æ¯ä¸€ä¸ªepochçš„batchéƒ½ä¸ä¸€æ ·</li>
</ul>
</li>
<li>shuffleï¼šæ¯æ¬¡æ›´æ–°epochæ—¶batchéƒ½ä¸ä¸€æ ·ï¼Œå«åšshuffle</li>
</ul>
</li>
<li><p>Batch size: Small Batch v.s. Large Batch</p>
</li>
</ol>
<ul>
<li><code>example 1:</code> æ— å¹³è¡Œè¿ç®—ï¼Œbatch sizeçš„ä¸åŒç»“æœ</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Batch size</th>
<th style="text-align:center">= N (full batch)</th>
<th style="text-align:center">= 1</th>
</tr>
</thead>
<tbody>
<tr>
<td>Gradient<br>Descent</td>
<td style="text-align:center">upddate after <strong>seeing all</strong> the examples<br>åœ¨ä¸€ä¸ªepoché‡Œåªupdateä¸€æ¬¡<br><img src="fullBatch.png" width="80%"></td>
<td style="text-align:center">update for <strong>each</strong> example<br>åœ¨ä¸€ä¸ªepoch é‡Œé¢ä¼šupdate 20æ¬¡<br><img src="miniBatch.png" width="80%"></td>
</tr>
<tr>
<td>Pros</td>
<td style="text-align:center">æ—¶é—´é•¿</td>
<td style="text-align:center">æ—¶é—´çŸ­</td>
</tr>
<tr>
<td>Cons</td>
<td style="text-align:center">ç¨³å½“ powerful</td>
<td style="text-align:center">è¾ƒnoisy</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>Q1: ä½†å¦‚æœåŠ å…¥å¹³è¡Œè¿ç®—å‘¢ï¼Ÿ(by GPU)</p>
</blockquote>
<ul>
<li><code>example 2:</code> å¹³è¡Œè®¡ç®—ï¼Œlarger batch sizeä¼šæ›´å¥½<ol>
<li>Larger batch size å¹¶<strong>ä¸ä¸€å®š</strong>ä¼šéœ€è¦æ›´é•¿çš„æ—¶é—´ç®—gradientï¼›ä½†æœ‰<strong>ä¸Šé™</strong>ã€‚<br> ä»batch size 1åˆ°1000æ—¶ï¼Œå¹³è¡Œè¿ç®—å¯¼è‡´æ—¶é—´å·®ä¸å¤šï¼›<br> ä½†10000ç”šè‡³60000æ—¶ï¼Œè¿è¡Œæ—¶é—´å°±å¼€å§‹æŒ‡æ•°å‹å¢é•¿ã€‚<p align="center"><img src="parallelBatchSize.png" width="80%" ></p></li>
<li>Smaller batch size å¯¹äºä¸€ä¸ª epoch è¦æ±‚æ›´å¤šæ—¶é—´æ›´æ–°<br>å·¦è¾¹ä¸º ä¸€æ¬¡updateï¼Œå³è¾¹ä¸º ä¸€ä¸ªepoch æ‰€ç”¨æ—¶é—´ã€‚<p align="center"><img src="smallBatch.png" width="80%" ></p></li>
<li>ä¹Ÿå°±æ˜¯è€ƒè™‘batch sizeæ—¶ï¼Œè€ƒè™‘å•æ¬¡updateæ—¶é—´ åŠ å•æ¬¡epochçš„updateæ—¶é—´</li>
</ol>
</li>
</ul>
<blockquote>
<p>Q2: ä½†æ˜¯ä¸æ˜¯larger sizeçš„batchå°±æ˜¯å¥½çš„å‘¢ï¼Ÿ</p>
</blockquote>
<p>å¹¶ä¸æ˜¯ï¼<br>åœ¨å®é™…trainingä¸­ï¼ŒåŒæ ·çš„modelã€åŒæ ·çš„networkï¼Œç…§ç†è¯´è¡¨ç¤ºçš„accuracyç»“æœåº”æ˜¯ä¸€æ‘¸ä¸€æ ·ï¼Œ ä½†ï¼š</p>
<ul>
<li><code>example 3</code>ï¼šå¹³è¡Œè®¡ç®—ï¼Œsmall sizeçš„å‡†ç¡®åº¦ä¼šæ›´é«˜<br>éšç€sizeå¢å¤§ï¼Œå‡†ç¡®åº¦ä¸‹é™ï¼ˆæ­¤ä¾‹ ä¸overfittingæ— å…³ï¼‰<p align="center"><img src="batchSizeAccuracy.png" width="80%" ></p>

</li>
</ul>
<blockquote>
<p>Q3: ä¸ºä»€ä¹ˆbatch sizeä¼šå’Œå‡†ç¡®åº¦ç›¸å…³å‘¢ï¼Ÿ</p>
</blockquote>
<p>å¯¹æ¯”ä¸åŒsizeæ—¶ï¼Œgradientåœ¨larger sizeå¯èƒ½ä¼šè¢«å¡ä½ï¼›è€Œåœ¨smaller sizeä¸Šä¼šåŒæ—¶è¿›è¡Œä¸åŒlossçš„è®¡ç®—ï¼Œè¿™ç§noisy updateæ˜¯æœ‰åŠ©äºæ‰¾åˆ°æ›´ä½çš„loss</p>
<p align="center"><img src="batchSizeAccuracy_reason.png" width="80%" ></p>

<h4 id="Summarizing-batch-sizeï¼š"><a href="#Summarizing-batch-sizeï¼š" class="headerlink" title="Summarizing batch sizeï¼š"></a>Summarizing batch sizeï¼š</h4><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">Large</th>
<th style="text-align:center">Small</th>
</tr>
</thead>
<tbody>
<tr>
<td>Speed for 1 <strong>update</strong><br>(<strong>no</strong> parallel)</td>
<td style="text-align:center">Slower</td>
<td style="text-align:center">Faster</td>
</tr>
<tr>
<td>Speed for 1 <strong>update</strong><br>(<strong>with</strong> parallel)</td>
<td style="text-align:center">Same<br>(with limitation)</td>
<td style="text-align:center">Same</td>
</tr>
<tr>
<td>Speed for 1 <strong>epoch</strong></td>
<td style="text-align:center">Faster â˜…</td>
<td style="text-align:center">Slower</td>
</tr>
<tr>
<td>Gradient</td>
<td style="text-align:center">Stable</td>
<td style="text-align:center">Noisy</td>
</tr>
<tr>
<td>Optimization</td>
<td style="text-align:center">Worse</td>
<td style="text-align:center">Better â˜…</td>
</tr>
<tr>
<td>Generalization</td>
<td style="text-align:center">Worse</td>
<td style="text-align:center">Better â˜…</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="2-MOMENTUM"><a href="#2-MOMENTUM" class="headerlink" title="2. MOMENTUM"></a>2. MOMENTUM</h2><p>ç‰©ç†ä¸–ç•Œé‡Œé¢æœ‰æƒ¯æ€§ï¼Œä½¿å¾—çƒä½“åœ¨åŠ¨é‡æƒ¯æ€§ç»§ç»­å‘å‰åŠ¨ã€‚é‚£åœ¨gradient descentä¸­ï¼Œå³æ˜¯ å‰ä¸€æ­¥çš„weighted gradientå‡å»ç°åœ¨çš„gradientã€‚</p>
<blockquote>
<p><strong><em>m<sup>i</sup></em></strong> = weighted sum of all the previous gradient <strong><em>g</em></strong><sup><strong>0</strong></sup>, <strong><em>g</em></strong><sup><strong>1</strong></sup>, <strong><em>g</em></strong><sup><strong>2</strong></sup>, â€¦</p>
</blockquote>
<p>æ‰€ä»¥ï¼š</p>
<blockquote>
<p><strong><em>m</em></strong><sup><strong>0</strong></sup> = 0<br><strong><em>m</em></strong><sup><strong>1</strong></sup> = Î»<strong><em>m</em></strong><sup><strong>0</strong></sup> - Î· <strong><em>g</em></strong><sup><strong>0</strong></sup> =  -  Î· <strong><em>g</em></strong><sup><strong>0</strong></sup><br><strong><em>m</em></strong><sup><strong>2</strong></sup> = Î»<strong><em>m</em></strong><sup><strong>1</strong></sup>  -  Î· <strong><em>g</em></strong><sup><strong>1</strong></sup> = -Î» Î· <strong><em>g</em></strong><sup><strong>0</strong></sup> -  Î· <strong><em>g</em></strong><sup><strong>1</strong></sup><br>â€¦</p>
</blockquote>
<p align="center"><img src="momentum.png" width="80%"><br>è¿™æ ·å°±æœ‰å¯èƒ½åœ¨local minimaçš„æ—¶å€™ï¼Œå†å°è¯•å¾€å‰èµ°å¹¶çªç ´ã€‚</p>

<hr>
<h1 id="P7-Learning-Rate"><a href="#P7-Learning-Rate" class="headerlink" title="P7 Learning Rate"></a>P7 Learning Rate</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11K4y1S7AD?p=7">Hung-yi Lee - Machine Learning 2021 - P7 è‡ªåŠ¨è°ƒæ•´learning rate</a></p>
<hr>
<h2 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h2><p>å‚è€ƒ <a href="https://beyuhu.com/TASK03%20-%20P5+6+7+8">Task03 - P5+6+7+8</a></p>
<h2 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h2><p>(æ²¡æœ‰è®ºæ–‡)  å’Œ Adagrad ä¸­ Root Mean Square å”¯ä¸€çš„ä¸åŒæ˜¯ RMSProp æ²¡æœ‰å– MEANå€¼ï¼Œè€Œæ˜¯è€ƒè™‘ä¸åŒçš„æƒé‡è°ƒæ•´å¼å­ä¸­ Î± å€¼ã€‚</p>
<p align="center"><img src="RMSProp.png" width="80%"></p>

<p>Optimization strategy a.k.a OPTIMIZER: <strong><em>Adam</em></strong> = RMSProp + Momemtum æ˜¯è¾ƒä¸ºå¸¸ç”¨çš„ optimizer</p>
<p align="center"><img src="Adam.png" width="100%"></p> é¢„è®¾å‚æ•°ä¸è¦éšä¾¿è°ƒï¼Œdefaultå·²ç»å¤Ÿå¥½ã€‚

---
## Learning Rate Scheduling
### Learning Rate Decay

<p align="center"><img src="LRD.png" width="80%"></p> 

<h3 id="Warm-Up"><a href="#Warm-Up" class="headerlink" title="Warm Up"></a>Warm Up</h3><p align="center"><img src="warmUp.png" width="80%"></p> 


<p>æœ‰å¾ˆå¤šé«˜çº§ç®—æ³•éƒ½â€œå·å·â€åŠ ä¸Šäº†warm upå´æœªå‘ŠçŸ¥å®ƒçš„ä½œç”¨ã€å®ƒçš„æ¥ç”±ã€‚<br>A possible explaination: ç»Ÿè®¡å­¦ä¸Šè®²ï¼Œéœ€è¦å¤šç¬”æ•°æ®åæ‰èƒ½å¾—åˆ°æ›´ç²¾å‡†çš„æ•°æ®ï¼›warm upçš„ä½œç”¨ä¾¿æ˜¯ä½¿å¾—æ•°æ®å…ˆè¢«â€œé¢„è¯»â€è¿‡ã€æ¢ç´¢è¿‡ä¸€äº›error surfaceçš„æƒ…æŠ¥ã€‚<br><strong><em>ref:</em></strong> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.03265">RAdam</a></p>
<hr>
<h2 id="Summary-of-optimization"><a href="#Summary-of-optimization" class="headerlink" title="Summary of optimization"></a>Summary of optimization</h2><ul>
<li><p>(Vanilla) Gradient Descent: Î¸<sup>t+1</sup> â† Î¸<sup>t</sup> - Î· <strong><em>g</em></strong><sup>t</sup></p>
</li>
<li><p>Various Improvement: Î¸<sup>t+1</sup> â† Î¸<sup>t</sup> - Î·<sup>t</sup>/<strong>Ïƒ</strong><sup>t</sup> <strong><em>m</em></strong><sup>t</sup></p>
<ul>
<li>ï¼ˆè€ƒè™‘æ–¹å‘ï¼‰<strong><em>m</em></strong><sup>t</sup> = momentum: weighted sum of the previous gradients </li>
<li>ï¼ˆè€ƒè™‘å¤§å°ï¼‰<strong>Ïƒ</strong><sup>t</sup> = root mean square of the gradients </li>
<li>ï¼ˆè€ƒè™‘scheduleï¼‰Î·<sup>t</sup></li>
</ul>
</li>
</ul>
<hr>
<h1 id="P8-Optimization-by-loss-function"><a href="#P8-Optimization-by-loss-function" class="headerlink" title="P8 Optimization by loss function"></a>P8 Optimization by loss function</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11K4y1S7AD?p=8">Hung-yi Lee - Machine Learning 2021 - P8 æŸå¤±å‡½æ•°ä¹Ÿå¯èƒ½æœ‰å½±å“</a></p>
<hr>
<p>ä¸‹æ–¹ä»¥Classificationä¸ºä¾‹ï¼š</p>
<h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><p>å‡å¦‚åˆ†ä¸‰ç±»ï¼šClass 1, Class 2, Class 3 </p>
<h3 id="Class-as-one-hot-vector"><a href="#Class-as-one-hot-vector" class="headerlink" title="Class as one-hot vector"></a>Class as one-hot vector</h3><p align="center"><img src="onehotVector.png" width="50%"></p>

<h3 id="Classification-operation"><a href="#Classification-operation" class="headerlink" title="Classification operation"></a>Classification operation</h3><p>input x â†’ Wâ€™ <em> Ïƒ ( b + W Â· <code>x</code>) + bâ€™ = output <code>y</code> â†’ <code>y&#39;</code> â†’ <code>y^</code><br>å…¶ä¸­ <code>y</code> å¯ä¸ºä»»ä½•å€¼ï¼›<code>y&#39;</code>ä¸º <code>y</code> é€šè¿‡<strong>softmax</strong> functionè½¬æ¢æˆçš„å€¼ï¼Œä¸º0åˆ°1ä¹‹é—´ï¼›<code>y^</code>ä¸º <code>y&#39;</code> ç›®æ ‡labelï¼Œé€šè¿‡MSEæˆ–<em>*Cross-entropy</em></em>åˆ¤æ–­</p>
<h4 id="1-softmaxï¼ˆå½“-binaryçš„æ—¶å€™ç”¨sigmoidï¼‰"><a href="#1-softmaxï¼ˆå½“-binaryçš„æ—¶å€™ç”¨sigmoidï¼‰" class="headerlink" title="1. softmaxï¼ˆå½“ binaryçš„æ—¶å€™ç”¨sigmoidï¼‰"></a>1. softmaxï¼ˆå½“ binaryçš„æ—¶å€™ç”¨sigmoidï¼‰</h4><blockquote>
<p><strong>y<sub>i</sub>â€˜ = exp(y<sub>i</sub>) / Î£<sub>j</sub>exp(y<sub>i</sub>)</strong></p>
<ul>
<li>1 &gt; yâ€™ &gt; 0</li>
<li>Î£yâ€™ = 1</li>
</ul>
</blockquote>
<pre><code>å…¶è¿‡ç¨‹ä¸º 1. æ±‚æŒ‡æ•° â†’ å˜æ­£æ•° 2.æ±‚æ€»å’Œçš„åˆ†æ•° â†’ ç®—æ¯”ä¾‹ 
</code></pre><p align="center"><img src="softmax.png" width="90%"></p>

<h4 id="2-Cross-entropy"><a href="#2-Cross-entropy" class="headerlink" title="2. Cross-entropy"></a>2. Cross-entropy</h4><blockquote>
<p><strong>e = - Î£ y<sub>i</sub>^ ln yâ€™<sub>i</sub></strong></p>
</blockquote>
<p><em>Minimizing cross-entropy = Maximizing likelihood</em>ã€‚Cross-entropy æ¯” MSE æ›´å¸¸ç”¨ï¼Œåœ¨PyTorché‡Œé¢ç”šè‡³æŠŠsoftmaxå’ŒCross-entropyæ”¾ä¸€èµ·äº†ã€‚</p>
<blockquote>
<p>Qï¼šé‚£ä¸ºä»€ä¹ˆCross-entropyå°±å¥½äº†å‘¢ï¼Ÿ</p>
</blockquote>
<p><img src="MSECROSSENTROPY.png" width="90%"></p>
<p>MSEå®¹æ˜“å°†losså¡åœ¨large lossçš„éƒ¨åˆ†ï¼Œè€ŒCross-entropyåˆ™ä¸ä¼šã€‚è¿™ä¹Ÿ<strong>è¯´æ˜äº†loss functionå¯ä»¥æ”¹å˜optimizationã€‚</strong></p>
<hr>
<h1 id="P9-Batch-Normalization"><a href="#P9-Batch-Normalization" class="headerlink" title="P9 Batch Normalization"></a>P9 Batch Normalization</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11K4y1S7AD?p=9">Hung-yi Lee - Machine Learning 2021 - P9 æ‰¹æ¬¡æ ‡å‡†åŒ–</a></p>
<hr>
<h2 id="Feature-Normalization"><a href="#Feature-Normalization" class="headerlink" title="Feature Normalization"></a>Feature Normalization</h2><p><img src="featureNormalization.png" width="80%"></p>
<p>å³ <strong>ä¸å‡å€¼mçš„å·®å€¼ / æ ‡å‡†å·®Ïƒ</strong>ï¼ˆæ–¹å·®å¼€æ ¹ï¼‰ï¼Œæ³¨æ„æ˜¯å‘é‡ä¹‹é—´çš„è¯ï¼Œé™¤å·è¡¨è¾¾çš„æ˜¯elementä¹‹é—´çš„è¿ç®—ã€‚</p>
<p>åšå®Œç¬¬ä¸€ä¸ªWä¹‹åå¾—åˆ°çš„Zæˆ–æ˜¯Z sigmoidä¹‹åçš„aéƒ½è¿˜éœ€è¦feature normalizationã€‚ä½†æ­¤æ—¶å•ç‹¬çš„zç®—å‡ºz<sup><strong>~</strong></sup>ä¼šå¯¼è‡´æ‰€æœ‰z<sup><strong>~</strong></sup>å’Œaéƒ½æ”¹å˜ï¼Œå¦‚å›¾ä¸­<code>Î”</code>æ‰€ç¤ºï¼š</p>
<p><img src="featureNormalization2.png" width="80%"></p>
<p>ä½†ç”±äºæ•°ç›®è¿‡å¤§ï¼Œå› æ­¤åªé’ˆå¯¹ä¸€ä¸ªbatché‡Œé¢åšnormalizationï¼Œç§°ä¹‹ä¸ºï¼š<u><strong>Batch Normalization</strong></u></p>
<p>ä½†ä¹Ÿæœ‰äººè¯´ï¼š</p>
<blockquote>
<p>This suggests that the positive impact of BatchNorm on training might be somewhat <strong>serendipitous</strong> <em>[adj. å¶ç„¶çš„]</em>. </p>
</blockquote>
<p>å³è¡¨è¾¾äº†BatchNormæ˜¯æœ‰ç”¨ï¼Œä½†æ›´å¤šæ˜¯å› ä¸ºå¶ç„¶çš„å‘ç°ã€‚</p>
<p><strong>ref:</strong>  <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1805.11604">How Does Batch Normalization Help Optimization?</a></p>
<p id="task06"></p>
<p align="center">- - - - - - - - - - - - - - - T A S K 0 6 - - - - - - - - - - - - - - -<br><a href="#index">[ B A C K ]</a></p>

<p><img src="HUNGYILEE_06.png" width="100%"></p>
<p align="center"> </p>

<h1 id="P10-Convolutional-Neural-Network-CNN"><a href="#P10-Convolutional-Neural-Network-CNN" class="headerlink" title="P10 Convolutional Neural Network (CNN)"></a>P10 Convolutional Neural Network (CNN)</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11K4y1S7AD?p=10">Hung-yi Lee - Machine Learning 2021 - P10 CNN</a></p>
<hr>
<h2 id="Image-Classification"><a href="#Image-Classification" class="headerlink" title="Image Classification"></a>Image Classification</h2><p>Processï¼š<code>Pictrue</code>  â†’ <code>Model</code> â†’ <code>y&#39;</code> â†(Cross-entropy)â†’ <code>y^</code></p>
<h3 id="1-Pictrue"><a href="#1-Pictrue" class="headerlink" title="1. Pictrue"></a>1. <code>Pictrue</code></h3><ul>
<li>= 3D tensor (&gt;2 dimçš„matrix) = 1D <em> width + 1D </em> length + 1D <em> RGB channelsï¼Œåˆ™å¯ä»¥å±•å¼€ä¸º **3å¼  </em> è§£æåº¦100x100<strong> çš„ å•è‰²å›¾ æ’æˆä¸€æ’ æˆä¸ºnetworkçš„è¾“å…¥ï¼›å…¶ä¸­çš„æ¯ä¸€ä¸ªpixelå¯ä»¥è§†ä½œ</strong>æŸä¸ªä½ç½®æŸä¸ªé¢œè‰²çš„å¼ºåº¦**</li>
<li>å‡è®¾ å›ºå®šå›¾ç‰‡å¤§å°ï¼Œè‹¥ä¸ä¸€ï¼Œéœ€è¦rescaleã€‚ï¼ˆå‡å¦‚100x100ï¼‰</li>
</ul>
<h3 id="2-Model"><a href="#2-Model" class="headerlink" title="2. Model"></a>2. <code>Model</code></h3><p>ä¹‹å‰åªè®²è¿‡ Fully Connected Networkï¼Œä½†ç”±äºå½±å“å¤ªå¤§ä¼šå¯¼è‡´è®¡ç®—é‡è¿‡å¤§ï¼Œæ€ä¹ˆåŠå‘¢ï¼Ÿ</p>
<h4 id="Observation-1ï¼š"><a href="#Observation-1ï¼š" class="headerlink" title="Observation 1ï¼š"></a><U><strong>Observation 1</strong></U>ï¼š</h4><p>neuronä¸éœ€è¦æŠŠæ•´å¼ å›¾ç‰‡éƒ½çœ‹å®Œï¼Œè€Œæ˜¯éœ€è¦çœ‹å‡ºå›¾ç‰‡ä¸­çš„pattern</p>
<p><U>Simplification 1</U></p>
<ul>
<li>æ¯å¼ å›¾ç‰‡åˆ†æˆä¸åŒçš„<code>Receptive field</code> ï¼Œæ¯ä¸ªç¥ç»å…ƒåªå…³æ³¨è‡ªå·±çš„<code>Receptive field</code> </li>
<li>æ€ä¹ˆå†³å®šå‡ºæ¥å‘¢ï¼šçœ‹éœ€æ±‚ â†“<ol>
<li>å¯ä»¥æœ‰overlapï¼›</li>
<li>å¯ä»¥ä¸åŒçš„neuronï¼Œå…³æ³¨åŒä¸€ä¸ª<code>Receptive field</code> ï¼›</li>
<li>å¯ä»¥æœ‰å¤§æœ‰å°ï¼›</li>
<li>å¯ä»¥coveréƒ¨åˆ†channelï¼ˆä¸å¸¸è§ä½†æœ‰ï¼‰ï¼›</li>
<li>å¯ä»¥ä¸æ˜¯æ­£æ–¹å½¢ï¼›â€¦<br><img src="receptiveField.png" width="80%"></li>
</ol>
</li>
<li><strong>ä¸€èˆ¬è®¾å®šï¼š</strong><ol>
<li>ä¼šçœ‹æ‰€æœ‰çš„channelï¼Œå³RBGä¸‰è‰²ï¼Œæ‰€ä»¥ä¸€èˆ¬åªè®²RFçš„é«˜è·Ÿå®½ï¼Œä¸è®²å…¶æ·±åº¦</li>
<li><code>kernel size</code> = RFçš„é«˜è·Ÿå®½ï¼Œä¸€èˆ¬ä¸º 3x3</li>
<li>æ¯ä¸ªRFä¼šæœ‰ä¸€ç»„neuronså»â€œå®ˆå¤‡â€å®ƒ</li>
<li>å„ä¸ªRFä¹‹é—´æ˜¯ä»€ä¹ˆå…³ç³»å‘¢ï¼Ÿ<ol>
<li>ä»¥ 3x3 ä¸º kernel sizeçš„è¯ï¼Œä»¥<code>stride</code> = 1æˆ–2 ç§»åŠ¨ 1æˆ–2æ ¼ RFï¼Œä½¿ä¹‹æœ‰overlapï¼›</li>
<li>é‚£è¶…å‡ºå›¾ç‰‡èŒƒå›´çš„ï¼Œå°±ç”¨<code>padding</code>æ¥è¡¥å€¼ï¼Œä¸€èˆ¬éƒ½ä¸º0<br><img src="receptiveField2.png" width="80%"></li>
</ol>
</li>
</ol>
</li>
</ul>
<h4 id="Observation-2ï¼š"><a href="#Observation-2ï¼š" class="headerlink" title="Observation 2ï¼š"></a><U><strong>Observation 2</strong></U>ï¼š</h4><p>åŒæ ·çš„patternå¯èƒ½å‡ºç°åœ¨å›¾ç‰‡çš„ä¸åŒåŒºåŸŸ</p>
<p><U>Simplification 2</U></p>
<ul>
<li>Parameter sharing å…±äº«å‚æ•°<ul>
<li>shared weight <code>w1</code>, <code>w2</code>, <code>w3</code>â€¦</li>
<li>ä½†ä¸èƒ½åœ¨åŒä¸€ä¸ªRFä¸­</li>
<li><strong>ä¸€èˆ¬è®¾å®šï¼š</strong><ul>
<li>æ¯ä¸ªRFä¸­éƒ½æœ‰ä¸€ç»„ç¥ç»å…ƒ</li>
<li>æ¯ä¸ªRFä¸­éƒ½æœ‰åŒæ ·çš„å‚æ•°ï¼Œå³éƒ½åªæœ‰ä¸€ç»„å‚æ•°ï¼Œç§°æ¯ç»„å‚æ•°ä¸º<code>filter</code><br><img src="filter.png" width="80%"></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>é‚£è‡³æ­¤ï¼šåˆ°åº•å·ç§¯å±‚Convolutional Layeræœ‰ä»€ä¹ˆç”¨å¤„å‘¢ï¼Ÿ</p>
<ul>
<li>èŒƒå›´ç¼©å°ï¼›</li>
<li>bias å¤§ï¼šä¸ä¸€å®šæ˜¯åäº‹ï¼›<br>  bias å°æ—¶å®¹æ˜“overfittingï¼›<code>convolutional layer</code>ç‰¹åˆ«ä¸ºå½±åƒè®¾è®¡çš„ï¼Œå¯¹äºå½±åƒå¤–çš„éœ€è¦ç‰¹åˆ«æ³¨æ„é€‚ç”¨æ€§</li>
</ul>
<p><img src="benefit.png" width="80%"></p>
<hr>
<h4 id="ä»filterçš„è§’åº¦é‡æ–°çœ‹ä»¥ä¸Šçš„è®²è§£ï¼š"><a href="#ä»filterçš„è§’åº¦é‡æ–°çœ‹ä»¥ä¸Šçš„è®²è§£ï¼š" class="headerlink" title="ä»filterçš„è§’åº¦é‡æ–°çœ‹ä»¥ä¸Šçš„è®²è§£ï¼š"></a>ä»<code>filter</code>çš„è§’åº¦é‡æ–°çœ‹ä»¥ä¸Šçš„è®²è§£ï¼š</h4><p>å³ åˆ©ç”¨ä¸åŒçš„<code>filter</code>ï¼Œä»¥<code>stride</code>ä¸º1çš„æ­¥é•¿ï¼Œç§»åŠ¨<code>kernel size</code>ï¼Œå¹¶è®¡ç®—æå–å…¶ç‰¹å¾ï¼Œå¾—å‡º<code>feature map</code>ï¼Œå†ç»§ç»­åšç¬¬äºŒæ¬¡convolution</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="filter1.png" width="80%"></th>
<th style="text-align:center"><img src="filter2.png" width="80%"></th>
<th style="text-align:center"><img src="filter3.png" width="80%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">STEP1: 6X6.jpg with <strong>64</strong> filters</td>
<td style="text-align:center">STEP2: calculate each filter(<strong>3X3</strong>)</td>
<td style="text-align:center">STEP3: 2nd convolutional layer â†’ <strong>tensor 3X3X64</strong></td>
</tr>
</tbody>
</table>
</div>
<p>æ¨èå¯çœ‹ææ°¸ä¹è€å¸ˆçš„è®²è§£ï¼š<br>ref: <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=AFlIM0jSI9I&amp;list=PLOrDt87s8A3pUSBVvY0g1vhuMk9RM0Ptv&amp;index=2"># äººè„¸è¯†åˆ«å•¥åŸç†ï¼Ÿäººå·¥æ™ºèƒ½ï¼ˆäºŒï¼‰å·ç§¯ç¥ç»ç½‘ç»œ</a></p>
<hr>
<h4 id="Observation-3ï¼špooling-æ± åŒ–"><a href="#Observation-3ï¼špooling-æ± åŒ–" class="headerlink" title="Observation 3ï¼špooling æ± åŒ–"></a><U><strong>Observation 3</strong></U>ï¼špooling æ± åŒ–</h4><p>subsampling:<br>    æŠŠå¶æ•°çš„columnã€å¥‡æ•°çš„rowéƒ½æ‹¿æ‰ï¼›å›¾ç‰‡å˜ä¸ºåŸå›¾1/4ï¼›ä¸”å›¾ç‰‡æ²¡æœ‰ä»€ä¹ˆè¿‡åˆ†å·®å¼‚ â†’ ä»¥å‡å°‘è¿ç®—é‡</p>
<p><U>Pooling ä¹‹ Max pooling</U><br>ï¼ˆâ€¦å»¶ç»­ï¼‰<code>Convolution</code> â†’ <code>Pooling</code> â†’ (repeat)â€¦ â†’ <code>Flatten</code> â†’ <code>softmax</code> â†’ output</p>
<ul>
<li>æŠŠfeature mapæ‹¿å‡ºæ¥ï¼Œå¹¶é€‰æ‹©ä»£è¡¨ï¼šæœ€å¤§å€¼(æ­¤å¤„ä¸ºmax pooling)</li>
<li><strong>ä½†</strong> è¿‘å¹´æ¥poolingè¶Šæ¥è¶Šå°‘ï¼Œå› ä¸ºsubsampleçš„æ—¶å€™ä¼šæŠŠå›¾ç‰‡å‹ç¼©ï¼›ä¸”è¿ç®—èƒ½åŠ›è¶Šæ¥è¶Šå¼ºï¼Œå¯ç›´æ¥convolution</li>
</ul>
<hr>
<p>cons: CNN æ— æ³•å¤„ç†scalingå’Œrotationçš„é—®é¢˜ã€‚<br>æ‰€ä»¥éœ€è¦åšdata augmentationï¼Œè®©CNNçœ‹è¿‡æ”¾å¤§ç¼©å°åŠæ—‹è½¬çš„å›¾ç‰‡ã€‚<br>å¦å¤–ä¸€ä¸ªç®—æ³• <em>Spatial Transformer Layer</em> åˆ™å¯ä»¥ã€‚</p>


<!-- Tags -->



<div class="tags">
    <a href="/tags/MachineLearning/" class="button small">MachineLearning</a> <a href="/tags/Hung-yi-Lee/" class="button small">Hung-yi_Lee</a>
</div>



<!-- Comments -->
<div>
    
    <hr />
    <h3>Comments:</h3>
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>



</div>



            </div>
        </div>

        <!-- Footer -->
<footer id="footer">
    <div class="inner">
        <section>
            <div>
                A little blog for note sharing, check the  <b><a href="/about" target="_self"> info</a></b> about everything! :)
            </div>
        </section>
        <section>
            
            </ul>
        </section>
        <ul class="copyright">
            <li>&copy; BH. All rights reserved</li>
        </ul>
    </div>
</footer>
    </div>

    <!-- After footer scripts -->
    
<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- skel -->

<script src="/js/skel.min.js"></script>


<!-- Custom Code -->

<script src="/js/util.js"></script>


<!--[if lte IE 8]>

<script src="/js/ie/respond.min.js"></script>

<![endif]-->

<!-- Custom Code -->

<script src="/js/main.js"></script>


<!-- Gallery -->
<script src="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->

<script type="text/javascript">
    var disqus_shortname = 'GUESTS';

    (function(){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>


</body>

</html>